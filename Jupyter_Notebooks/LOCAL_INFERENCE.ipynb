{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afce2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07ea162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb68b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb165d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmin_h: 9\\nmax_h: 177\\nmin_w: 24\\nmax_w: 512\\nmin_ratio: 0.42857142857142855\\nmax_ratio: 35.357142857142854\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")\n",
    "'''\n",
    "min_h: 9\n",
    "max_h: 177\n",
    "min_w: 24\n",
    "max_w: 512\n",
    "min_ratio: 0.42857142857142855\n",
    "max_ratio: 35.357142857142854\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6c15cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ResNetTransformer(dataset=dataset).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4390ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Printed3_nocompression.pth\"), map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab200a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LitModel  = LitResNetTransformer(model=model)\n",
    "#model = LitModel.load_from_checkpoint(\"Models_Parameters_Log/Printed2_inverted.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427cc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "# Helper Function to convert prediction labels to strings\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ccebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose([\n",
       "  LongestMaxSize(always_apply=True, p=1, max_size=420, interpolation=2),\n",
       "  PadIfNeeded(always_apply=True, p=1.0, min_height=420, min_width=420, pad_height_divisor=None, pad_width_divisor=None, border_mode=0, value=0, mask_value=None),\n",
       "  CenterCrop(always_apply=True, p=1.0, height=250, width=420),\n",
       "  ToGray(always_apply=True, p=0.5),\n",
       "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
       "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_transform_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f89dc9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 424, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> n : = \\mathrm { c l e g } ( f ) = \\, q ^ { 3 } + { \\bf 1 } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> n : = \\mathrm { c l e g } ( f ) = \\, q ^ { 3 } + { \\bf 1 } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/my_image.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "\n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    \n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5acbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 516, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAD6CAAAAADL1GzaAAAFRklEQVR4nO3ZW4hVVRzH8d/aZ0THGa+TimgZE+GgWJHkmxThg5YVXYSoJpAoyiApoQcllRCiKR+UDEIQSejClCnZQ/mSTUFmRkZiCVqYjag44y3HbM759bD3PmfPTec4Xg76/TzMrPtee/1n77XOGQkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgJI/ehbt/uzKT+OaFg2od5AbcsXc842NY6RHNNgbyhhhTGPjY1I0aUATuca5ZNOY8nvXhSQ1aJL/OnTIXzVYQf6wvwNUx5eeJJd97evIrTeesMfV19dPcMFDy3uwonmH0xjJfjL+ZUnf9XPJo9HOt9TX1zjuhj61xQsUtNmeUVbPJzwvSUXrPF+SotmeEEn1/jfbLgrvrlnzZvHV2lyqsZslRZpPkM6vPV2gZ+znwvnbdrXxeDHpj+Oej/t2SWo9NjjTbqR98gd7SDJ4KR5NnX4wSFL4uGKDNLBd+3J4r6y1eviTUro66dm+S5JeGz0x025hYejwGTWFjqTJnmLF8Zw2W5KcU6WqvCAtiP/YmySp+FCFeJ6ZdYyS+rq0wIU5ceKrWZKkWn+dGXV5rkM6k9sSBymfL1aMyMuntkrSY/dcmhu4VqWvu9wjzi+RcpPfse1N8cFvxFG7Rra36w3bO+LSFZKk7D7igtevzAQ2W7dvR5LY5E+XL/WuzLWTc+WZZXWV+yhVhCRI0yfarZKGu1PSL4VVQa/avsO2tN32jdKRzh2+QcPyrpWkjq5Bct6eVsxn6tYtSFMtLfE1UtHY4vm/qqzd8LrTbnecPdthW0HS1sIBSUNsxQfquz1Pkj1YSte+3R9JXYOUPhOl7Iu9XmzI4K7B+KcYpUt4R5dU1dWeQGr2UEnVG4MlzdJNks4mNfVhW7Kq8aF6Z5zpsaQhaO6R7fLmh9KS3t9fZ7vla6aOapHyOfnk8AHcwGVUGUGytK2YktSZjUBtt3C0ltqVRAVZ2hIF60wvF3g21/WEVPNWJrM7CtKGpxxce7r8uV8BlRGk7ptBujtEhf72KDhIUiGEXl9aa08f7pLfVkytWFLXVpD0dKM1fBxBupwW7ot/e4+GpWWuLtXX9tXxjNqCJVmfP6Cceo/xVVZ5n5Mk7VV8wG5b3d8euWOdSWqs5qaFYWe/+iYHhtChv/fm6hYe2v/FS41JqL7p8cRer6Lid3epRT4sRZpmBdk3J6W2FCRvlILa/H5allSOkCS97tm5TPsLW+zC2umSNNdeLVlfHlG65f15zkMHcGPXFNsu2MuLBaHR3qLxXhSqbLtpmKSptv1ofMy+T7bdKUn+IBmj3a+MGjWqqfO/dJAXCpkgtbibYs1it59LypqCtENepTRItqdcvtvuv0rZk4I0qJjxhp2777caflfDlCAdPVIt/Tq5Stod1JA7dWDi6ClBJw7e+ZOUnOWav5w9vnWlpNp/0kHOZd9UM2/rVNapYqqmffT46KAk3bJfCndJL0vrk0l5QqsgnWdbDJkGSaOqUnH81XXzvq7DlAb7/mS/N9yQ+fm2Je1rTgZjS7oUlpa+Buqm//+a7drtoCQv05yLnhJ6+LmPF9KWizxL+15JVp8f0FC+kOv1H+5B/vHiBpw5Ugo3z71gO5Qhksf0iFIU/O3VmAz61MuLLf/blZ8GAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcJH+B1YnFXQEyIL7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\mathrm { P e r m } ( S ) \\cong { \\bf S } _ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\mathrm { P e r m } ( S ) \\cong { \\bf S } _ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    pass\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7f98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 658, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAD6CAAAAADL1GzaAAAHUElEQVR4nO3cf4wU5R3H8c+zw8HpcXA9LL+K9JSrNUoTLdiCgRCUAldrFWzThv6ihfgDKsGCmvQaTQNVlGC0idWkUtumjVKrhdZCI8UohdqkP5AS9KStpCRCEPAOpHDg7Xz7x/7e29uZXZeb3fP9+ueeefb7zHx3np1nnpmdPQkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADoy8wN9of1USeBADdZ1Bn0n1jUCZRrZtQJIJh9KuoM+k/NHkk6GXUCCHKrSXJTo04DRbg5GyTp1YjTQFG2VE4foAleLYp39/h+N50EAACQx0WdQEn6mM41d/ZvGijC3eZbXj+tW2vx/DpEa3+vXpLm0klVxszaew3R/u4oUqlt7+ODHdzUzL85VLOG8rN4f+avrvQaz8HEwZwktfndqn/BxrY6NWwO3faGjYPfKx6xc6orkLQXz112g99pkKS2/zkb8Rt9/ris/oXQWSRddcEpq9vzttRycVzv/Tl0u1P3VbybKu1I8iPszDxJf7f75YVuHLvmsaAQsxDnoJZEiKf1tkeSsy2Phs4hZ1sXSZIes5J2++kh5WysH302vQd/bC1yF5c69oUa8H4XFPPmimRhsB2W9J9XSswi6Zv+upBJ5eh4sbzN9Rublyot8a2M89PR/UERtxeY4eWZkAkwmym9XmoWSSPjJpXxJqpzulnfLDU3Szn5me8FZzu0SWoekVVxNqiFW9vXgNdcJzWdL+mSJ9OnrWvN9GbQmXfIh1xuEinmXxG8y4c059dU5cV1vR2Zt2jT8ybNyXpHS3L3ZcE9tev152zd9q3ZXVssPBlitrdA9b2/tum27b+3SPbLTG1nz96gPlr92kJr27KsQGfM9VfJ1mSWC61p6s63bpPOz2793MGALUbhT3rRlyf7iGZk55r3gbcsyarrlzrZhkRgcnphRcJTfIvf2mt/1e2SmbTYcjrJ3WGPZEetzFrrDcm6v8Vkp/OzTSVx+51eznJ+Up5pvUk3m5R5rqcaO6lHm81J9rBm/DZTa8cDjySTZC2JV1aOT1Rt6Ts8ZW6PWWt+ZUOrrEVabCNl49K1o54yCziSTJLNSpRn/SX3tadtcXbrAmtqnCAbIx18XJK+cSpRWY2dJNlwSTZaMx7MVN0teyPEI2OpnmxKxNq/wmzO4lf3rl1mkr6cM12pMz0f5jSeijlvTE61uyNE4+Umyb4lSY3Jo66ynTSoUity0j0y6c67khX2wIMufomfFfLhrDd8NF06cSCWCOpKVnysaHjCpR0LClxcNkrSU5K08cZETd1Zp8/Z8eGZmPqhmbJ3OFX6Vapw+nTOGu2hvE2MzHpD7yTLQyVN1k8k6d3eSVVAhTppjbqk7x84nKlpW9tuGuT/bGF6V3uLMo8Gj5ic+PvFZzRomO/+Ob3Le2NC7lji3f2JdLlxmp/zmjp++kyBLFZ/VbpMs5R6ctLZWSd5XU1ZMd0vd6XLCxNRbZs1TtJ3OjbLbNhJSeMPJCMaNCVnC7G5X0mXR12RLKxaIJ2QpBVfmHJetyRV5/OAu6xeM+xCaaxJcpLF66RY4ZNxxqVn1l1n81zrDslSI06owalg0GjbKtkhSU/+QpJ0WWqVu4quzT96oa2WTHpcf1whabuNliQ5TbLpIbKZLdlDMelLsmmSpM54QJNI2Nf3/fvQOCfJpihz66bQzCzbYHvp/qn26nZJWn5fou5M8O3EPtY5xf66xz4pSRM7JbUmN77bzGxhsdW9tHu47TVJ+qhJ0o/s6tSGwtyDqrM95j8rpZ8E9I4FtolA5l6QVpZ7tW03SVJs37CgQLemj03YE5niovKSGP904u9nSm2YSOlrJYwG/e7GAhejJbomOd4FN7/HxhZ+wX6YLs66t7wsTC9L0hNXldLGJPt9TJKWLZUkhb9h3o+uN7suvbC8zF7acUySip89JKndLs8fEJ1J0vyeTZnee3dSWUkMem2Skxr94MgM00TbmJh622xJbvhbZW37HPtBe/sD6QVvwXfLX9P+bYEhdmX+tZf37SOepPb29olZYXXlZ1FiBz+6SpK8W9zIvZJ0UXLaUdXcteW3/XhghJ3Kr/HusskFAsN/iVUh3dtshCT1MRh/gPSebE07ZiWNTudO07laccXuOPSPTRqV+aC27FTiy/ru6BLK1hV1AtVha9wK8McEt6xpNXUkuSXzC1U3HervRAAASKitX4JUQA3+s419n85dnhNNGihmds5S58mqvOWMXAO/k2puuLMz4R//Hyhq6mJWkrkr/yHtSM4dLgi+IYsojHk4b3Y38Ie7WjuSpIPPml5JHUm9npAckGrvmsOclPr9j+tW6kdrqCZ5Xx7ZiY63B/6AV1OWyr4XdQ4o7nL7OUdNtePsAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOj9H7l2gJtl/9Y2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1d10c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "#Thresholding\n",
    "ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image']#[:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c580c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 178, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> h ( a , b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { n } } \\eta ^ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> h ( a , b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { n } } \\eta ^ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc374a31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 57, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAD6CAAAAADL1GzaAAAFk0lEQVR4nO3ay29UZRjH8eecM5d2pnNpS69AW+iFtkDBFBAIRQ1CouLKqBt37vxT3Ll35dKQmKhxoQSMGiUWUGipgNA2tNDLtHPpzLSd2zkueplpizBNOsy8ne9nMznvnJ48yW/ea48IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCMaMUuYJv0YheAl1PtR7UzPJ16sLd+cKjYdeTJVuwCXgXdsExTdMtaa/CesobPv6Y/iWWKWVbedv9wp4nUdrdWieZxrrfZvNr00OOaHlcR69qG3d+TLMPf2aqP35WG0PLKb9KyFh/NPmmPJLJdq7Tt/pCkqW+P70DjfHxPMmjYxBLNWg5dD1st7bduqTHalcPCoanL0Jt9iYnxBb3SYYkYycC8SNtp3407xS4tT2XQk+Yi6UzmzCfOq/Yej9O0xLEYFekeGP/RtW82Wezi8lIGIaVSIjIVXk6lpkOGJWIkZz19bx+eaw2MBgmplGSGA0bm6dpV3ZE2vcv/+0MWDiVE9/rmAjmJxP6asVUujj1ToyOVw8JBRBwd1aGZYDYl3WFYurlsFrGk7SiPnqRVGbPzOddmUkRTZZdULiFlAlp4Q4MqfaisaOUxrBeftuEjr3tfejapxtGlUr8wtzOVSOU5k+hOpy2zmBCj0mXXnv83xnIotYPVFY5Sc9LZQxMjY+mX36dZIs6+/saZn+9J7Zk3Oiqeu9TWam98MbbTJRaESiHVvjtwLfAkj5AskbrTh0zf/oWpYB63lzyFQtIPHu++nedgV9n7cfzzug/aT92cu/rHC4a7HSyvgFQJSbOk670ue5Urv0n0wmXHb4+XIi3Hx+fi8RfcpyuxFldjeSNiiXQcMyd1T14Fuy9fGvxavAl3vWNDu6br2obFkhIZKdOTxNNeNVJTU+HOpye5+9qth0GxV3kXjNx2x7nDmT9vOvfNRgtUZIEoE1LLhac/uAZcnmxImrZhi2pZ6+c8HRd9j+dFGltcSxvWDfUHj2qRR/6GKCEVRk3v1L3X05U5c5LhdBjZFYGWSSYyq5fN/bbJSqezpdUezd0ItbXeH/XJiUxEjd1RliIh2fc2jw6Fp+J+73pImrfBX5l9ScFIhGbCq5ct/dFo64B24tCDsVjOQ/T4+FzVwLkHI7mNKlAkJP87ju+HxEw4sz1J8+xv8mT7hD0+tRxdDam6bklr9ho9jYOjuQPbk6dpiZl7H868qqp3iiIhtbzvjtU0nN9XW7EekhUZCzjN9fHOSMbWOlJVs+P+dwlPnaFPD0dyHpJOi0gooMjmKIcSIemeLm/92R5fZ011Tkjh8PPvttd607d/Eu/J+dnR4JZvF+5MF6rMgin9kDRLzEv9VyZDseqjF9+ozrbXNvoqcuakZGR65QzI5pZwSKTiWMXgv5sfZvO6w6rNSCqEZIk0HnNcmRSR8YYBf3Yz62pqzJ2TFqeiKwOZmYjFEiId5zPfbHmxzl4j05HNjSWv5EPSTak+PvdgSUQkGtXt2Y1PZGy+IndOioRWzg8SgbgzI9LSOXRt6yG3GZp/0TFRaSr5kMzq3ouHU786RVwHjx5xtH10PRA1RUSsWHJ2wz4plVw95FmYCDR2H+i+fXVMNh+tpiNJxTayIgqEJN2fveVKxq4/k/1vnjuZ2fOp/9vlhIiIZFY/12RfLBm91/Bh7/SXt0Q2H3+n1VvaiQohBX6ZMJPDQZGFf5b+1vXUSGTtVPR/X/e5+5VDn5kcXNz6jTpvCClF2/RZjlT5V8V2QirnPAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgl/kPgAS5/kHxWQYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xs(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da57a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 1080, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\rho \\left( \\frac { \\partial \\, V } { \\partial t } + \\, V \\cdot \\nabla \\nu \\right) = - \\nabla p + \\nabla \\cdot T + f <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\rho \\left( \\frac { \\partial \\, V } { \\partial t } + \\, V \\cdot \\nabla \\nu \\right) = - \\nabla p + \\nabla \\cdot T + f <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image']#[:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d2f77cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1404494382022472\n",
      "(140, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=480x280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> X ( t _ { n } ) = T _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( \\beta ) } \\sum _ { r = 0 } ^ { n - 1 } \\int _ { t _ { r } } ^ { t _ { r } + 1 } ( t _ { n } - \\tau ) ^ { \\beta - 1 } F ( \\tau , X ( \\tau ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> X ( t _ { n } ) = T _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( \\beta ) } \\sum _ { r = 0 } ^ { n - 1 } \\int _ { t _ { r } } ^ { t _ { r } + 1 } ( t _ { n } - \\tau ) ^ { \\beta - 1 } F ( \\tau , X ( \\tau ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xl(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8fee88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 1774, 3)\n",
      "(125, 1100, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAEYCAIAAAALd7K2AAAVTUlEQVR4nO3df1RVRQLA8Xk8UBT5lfxIUPwRGmnq+rNWhRYkQ0VdQYVdYTtrpu1Sj9SktfxRbSu67Z5jmlvqnhXrVJpsmbpQSts+a1XyWBKkZZuaR9AgENAIFZn9Y45zru+XvOeLyr6fv+6de+/cee/dO3dm7sw8IQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAm4qKiqSUgYGB33dCAOAnIyAgYP369SNHjpw3b15BQYHJZHK2Jxk0ALS38vLyhoaGoKAgKeV3l0Hv3bvX42OBnybf7zsB+P7FxsZ27ty5Z8+eQggpZUlJidlsVptMJlNOTs4nn3xyPfH7+vr+4Q9/iI2N7du37+eff+6FFAPAj1F4eLhb+4eGhkophRAPP/zwM888ExIS4mxPKWXHjh3bEue5c+eklB9//LEOeeedd/r06eP6qMGDB7cpxQDwoxMaGvrWW2+p3LbtMjIyXnzxRSFEWVnZxx9/HBQU5HC3zZs3f/XVV21ppti9e3d8fLyU8uzZsyqkY8eOzlL10EMPqYW5c+e6m3IA+NHo1q3b0KFDv99srkOHDlJKf3//vn37BgQEqMC4uLjdu3erZavV+uabb+pEHj16VB9LBg3gRtajRw/PsrkObeDi/aG2aNGi//73vzaB06dPl1IOGDDAZDJJKbt06SKESExMbG5ubm1tbW5uTktLE2TQAG5snmXQN998s5RSSllTU1NbW1t3tZaWFrV106ZN14xKSrl06VKHm1T+/v777xsDjx07ZjzW3ZR/F9LT03NyctryNAIAN3hcgv7Tn/4kpZwyZYqzHaSUL7/88jXjkVL26tXL2dbo6GibNu4RI0aohdGjRyckJLh4Rdk+iouLZ8+evXTp0i+++MLFbuPGjWu3JAG4QXicQQshTp48KaXs3Lmzw61DhgwpLCx0HUNERMQPpBTsmcmTJ6v0FxUVvfLKKw73yczMrKur++c//9m+SQPc16lTpw4dOrje53svEylmszkqKqp79+5+fn7eijMmJiY6OjoyMtIYaDKZrtnR7TuqPvv5+c2cOdPj4SSdO3eWUn777bfOdnjttddcx7Bjx476+noPTu1C9+7dvRuh1q1bN5uQ0tJSKWVzc/OWLVtcHJiRkdH2DNpb6Q8MDPTx8bEPj4iI0MuhoaEuYviB3Ik/EepFi9FNN93kQTyuBqrMmjXrwoULQogLFy4UFhZOnDgxJCQkNDT0ueeeUymoqKhwUZ9V6uvrq6urjZdRGwUFBe3ataugoKC5udlsNvv6+k6ePHnixInuxqPExMSUlpbqZAwYMGDo0KGtra1BQUEvvPCCv7//tGnTfH19t2/fXltb28Y4T548uWbNmmnTphlv9Q8++CApKcn1gVLKI0eOjB49uq6uzrOP41CnTp1qamqSkpJGjRr19ttvu3t4U1OTxWJZvXp1Tk7O2rVr7Xd48sknXccQFxe3a9cud8/rwurVqwsKCk6dOuXFOLWampqKiorbb79dh4wcOTItLe2NN96QUhYUFJSUlGRkZOg6wcWLF7du3Wofj7ovTCZTYGBgc3PzuXPndFVj7ty5ra2tGzZsuGZi1L1mMplqa2uLi4tnzJjh5+cXHh6+atUqIURISMjevXv79+9vc5TJZBo1alRsbOxf/vIXIURDQ8OJEyfsb0mz2dzS0iK+s5IBbFit1gkTJtgE/uxnP1OvN7x2GrPZXFlZqS/Q9PT0yspK/Ryuqqoy7vzKK684fMILIfr3779jxw53z75mzZo77rgjPDz8/fffz8vLCw8PLysrczcSrVevXocOHTKGPPnkk1LK+fPnCyF8fX2llKmpqb6+Dp5Yw4cPtykma9nZ2V9++aVeXbp0aUJCgl7NyMhwUYD6YbYGlJeXe5yw+vr6BQsWeCslY8aM+fOf/6xXu3Tpkpqa6q3IlZEjRz722GNqOTw8XEp58803m81mKWVKSoqvr+89Bvq5a1+CllLu27eva9euAwcO1FWQyMjI//znP21PzNmzZ/U3f//99x87dkyXuaqrq10caLVadd49ZsyYf/zjH/b73Hfffdc5HBRtZLFYFi1apFcPHjyYn5+vlr3/E4wZM0ZKuXnzZj8/vxMnTujwfv36bd++3binlNJh7qZUVlZ6VsJXMcfExHh2rGafQauYv/nmGyGE6zdCu3btSkxMdLjJJoO+fPmyzYFDhw51Fu2yZctmzJjhcFNra6uL9HzXpJQHDx707EDvJsNYT8zJyVm5cqUX4xdCqG5/annSpElSyt69e0+ZMqW5udnFUQ4z6IULF6plfV+o7L7tiUlJSZFSPvvss76+vsZBmCNGjHBdBg8PD1c1XcVhteyjjz7Kyspqe2LgMeNdUFtbO3r0aL0aFBR0+PBhL5/v7NmzFy5cOHLkiDFw7969+or09/eXUjY1Nbm4P3fu3PnAAw/YBCYnJ99ztbCwMJt9VMPo9X8Khxl0Xl6efavr888/bywFnzp1SnUyM37RmjGDHjduXENDg94kpWxtbXWR1U6ePPnMmTMON9lk9O1sypQpUsrMzEy3jsrKyvJiBh0cHGyMraSkREp58eJFVePxjJoNSvP39xdCNDc3q9royy+/XFFRUVRUZLVaXcezf/9+q9V6zz33qNWBAwdKKe++++6EhARjBcKYfl9f39OnT+tTOytwSCkbGxsPHDhgDPzss89mz56tV/Pz83U8K1as0Afqh1lZWZl+8IeFhdXU1Hz++ec6MRaLRR/+wQcfuP6kcNegQYN0JrBu3brDhw/bFEy9X/YaNmxYa2urTRerpqYm42pqauq2bduE80au6dOn2799yszMnHlFVlZWVlZWVFSUzT4xMTGuizPOBAcHG1/EO8ygVQHKJlv58MMPf//73xtD9A7JycnFxcV5eXl6kzGD3rdv34MPPqg3+fn5qQOdfSdq0J3DrQ5/RR8fn+Tk5ERvuOa0GGrIuFtvDlatWuXFDDoxMfGdd94xhnh2ZRu/XjVqsbGxUU8FJYRYsGDBxo0bhRBSymXLlnlwiqefflpKabVapZT6boyMjFSVM0XdPk1NTSaTyUVDcGJiYmtrq852FeO3euutt06dOnXlypUjRozo1KmTDje+DZozZ45qEtEl65CQEBVJZGTk/PnzU1NT58yZo55P8K61a9fqbKelpeXVV1/dsGGD8Rf0fgZ97NgxlYsZ+z+cP3/euM/x48ddvxlLS0vTMzO4Zfz48f/+97+NIW150REaGrpkyRLj9+Iwgz506NDy5cullD//+c+dRTVr1qyTJ0+qZRXh6dOndd8VYwZttVqNBajf/va3rjsDqIZv48epqqqSV1PviBRVU/EKY9uuM1LKgQMHXnM3bdu2ba6bSt1y11137dmzR6/GxcW5ftqJKw88Gzb7jB071magY25u7vr164UQra2t9hW4tti+fbu663r27Kknk4qIiLApxHTr1u2aD7AjR46oZBtbC+2Psrn7hBDl5eVqMkIhxH333aeuWKvV+sgjjwgh7r///pKSEr2z6wY9XI+1a9fqzk46Ly4sLNQXszczaNW8EBAQ0K9fPymlmlJHaWxs1F0X1EsV9UAODw+/ePHipEmT1LsmXe3avHnze++9ZxN/Q0NDy9VSUlJs9qmrq8vIyFDLx48fP3jwYFlZ2aVLl+bMmVNWVubiig8ICHCdQX/xxReqT8ilS5cuXrzoLJ633357xowZHTp06NOnj6p7zp49W7eBGDPo3bt3G9sKq6qqpk2bpkpMlZWVe/bs+fTTT6WUkyZNUjskJydLd0rQ7amiosL108We8aNdv/j4eGOr2vLlyzdt2qSei1VVVQcOHKiurpZSupulrlq1yqb2cOrUKc8KzlpNTY3qI2EUFhZmbBcWQtx7770uWo3UfFImkykpKUlKuXr1ar1J2lVl7FuZpZT6fnzvvff+9a9/qcDBgwer2zM+Pl7vbCzaw7v+9re/6fcT+i5+4okndO8mr93auoau1NXVSSlVFw6TybR+/fonnnhCberUqZOUsqSkZMCAAUKIsrKyQ4cOmc1m4wW6Y8cO3WbnlsuXL+vLOjMz89y5c0KI48ePqw5Pqq32zTfffPWK119/Xe3sOoM+ePBgamqqyhxXrFghpXzppZfUpm+++UZPsSaEqK+vnz179rp16x544IHS0lIhxKxZs1SlWFydQffu3fvSpUv6QCllXl6e6v+Uk5OjEmNM0oQJE4zlGiOPf0Wv9KN67LHH3O3/FxgYKKU0dlm7Tqo4rFf379+/cOHCiooKIcRzzz2nipDy6lpdW1RXV48dO9Y4DrC5ufk6k93S0qI6ntqwKT28++67kyZNUkXa7Ozsr776Sm+yaXBvaGgwrhYWFhqbzhISEoqKinTHAH0uXas7dOjQsGHDhBCnT5+eOnXqmTNnzp8/r+8Lf3//6upq3Uw3ePBgz6q2cEaX9srLy1WucuHCha5du4orZVnvnGbx4sUWi0VdyoGBgQsWLMjNzTV2H1F5pTrro48+euutt6pVlYLJkycbu3l4lqxly5ZZLJYlS5YEBwcLIfbv368aqVVsixYt2rhxo8lk6tevX+wVffv2Vce6yKBXrFiRm5v7xz/+Ua3m5eXl5uYuXLgwOjpaCJGWlmY8MDs7W3VdDAsL27dvnxDCYrHoTh02vTiMtdqHHnroV7/6lVouLy+PjY0VVxde9u/f76wTnsVicRhuMx1zRESEMUe2f+fz0ksvff3113//+9+FEMXFxQ7jNDKZTGFhYR78WL169ZKGFliv2LJli25jmThxor72Tp065efn16NHDxf1HmcsFovxZbWPj8/XX399PYlcuXKlxWKZN2+e/euT+fPn6wtACJGamvrUU0+p5ZiYGON74Mcff9xisah2tu7du8+fP19dkGpr586djR2oevToUVhY2L17d/3T33nnnX/961/1Dvrni4+PX7hwoY+Pz9y5c3/zm9+oQH9//127dvXo0UOtRkdHG99A4voZb59HH3106dKlqnuoyWRKS0tzt2Lqud/97ndTp061CYyKilINkdu2bXv22WdVqTk/P//OO++8/jPqT65KsocPH16zZo2L4o/rJg5ndu7c6awqqiI8e/asbiK0yaC7dOli3/VVvYrs2LFj//79P/zwQ1WW6dOnT1vmHrKRk5NTW1t79OjRgoKCdevWGT+gfa4qpRw0aNCwYcOklD179gwICDCW2pyRUhrfPtlw9kRRIxjb9iHc0NjYaB+oTjRjxozNmzcbm9088O6779qP+PIi+8ZiJSUlxa0b9amnnjL2LLJh/OY3bdp02223tT1meJ2q4jjc1NDQ0K5jhRYvXhwXF2cMiY2NHT58uBAiMzNz0KBBQojs7Oy77rrLK8lSz4P+/fv/4he/EEKkpKQMHz7cWczZ2dnp6enjx49XqzExMVVVVS+++GJbuqa66Hdx77336tx5y5YtVqv1008/Ne4TExNjMwzPbDarSYgGDhyoenT5+Ph4/CD93//+p1tj1q1bpxZeeOEFVcnQ1q9fr+7bUaNG6bap559/Xn11zjQ1NS1YsMDFj/XLX/7SYfj58+d1qrzLZjzUTTfdpN5JDBkyxONhpcrWrVvb4T9w6+rqvHLxr1mzxuFYbWNj1COPPOKi3z3aTVZWlv1jcsmSJW69dW8/DDD1ImMGLa58tzalV9XUJaV8+umn6+vrk5OTVXhUVJTukWLvtddecz1Wc/ny5c4y6Pr6+sWLF7f5Q7iH68cZ+2+G7+qHjF/nxmeTQQshbrvtNpsMWnUJyMvLGzx4sJRy1KhRKrxLly4OGyJMJpP6kyrXpzZ2FbDf5GxUJACP8a/eP3r29XTVjFNUVKS6PZSUlKhJRJ01iUop9+zZk5CQ0Lt3b4c7+Pj4qCGqzmIQhrnu1OtZm17AAHDjsy9B33HHHTaF3+LiYh0ipaysrNSbHBaTrzGsxcBho+2GDRuMLcUlJSW6UQUAfkKOHj1qP12ZlNI4laCUsrS0NDg4ODIyUko5c+ZMFd67d+/voq/Fl19+qfvhqxl/Xn/9dWdTGwLAjUkNF5JSvvHGG8bwAwcOGAebSSlPnDjR2NgopXz44Yd1+Jw5c4xD1Nyi+7lrXbt2VfM/XL58WZ/d39/fu5NcA8CPnhpEI668M3TYFtHY2OhiSlgXPvvsMx8fH5vSt5TyzJkzjz/++LfffqtfT8+bN08NluvQoUNQUFBAQMA1/3MHAG5kJpNp/Pjxak6JZ555xjjwV9uxY4ezYSbTp0+fPn16RESEs0Flaq6JBx98cOzYsTrwo48+klKePn3auKeUctWqVWrQv5QyPT2d/1cFPEYvjhuBlLK4uLimpkYIERUVlZSUZD8MOjc319l/R23dulVKmZ+fHxISEhQUVFBQoDc1NjYWFBSosnNdXd2YMWP0LKBDhgwJCAiwmXlHTXL9ySef3HLLLRs3buTPVQHguiQlJbmY4WzChAlqEqhf//rXbZ/FPz8//wc6bgoAfkRKS0vT09PVcnBw8FsGqnezmtln586dLibOtse4KeA6cQtBXLp0yfW8natXrw4NDe3WrRsdnAGg/VDOBQAAAAAAAAAAAAAAWnR0tIv/wWsfQUFB6p93259x/LQz48aN0/Puu+v22283m82eHfvTERcXp/7cs/3Fx8d/L+cFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC4Ifwf36XcF4HIJfsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=480x280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> X ( t _ { n } ) = { \\bar { T } } _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( \\beta ) } \\sum _ { f = 0 } ^ { n - 1 } \\int _ { f _ { r } } ^ { f _ { r , n } } ( t _ { n } - r ) { \\cal { C } } ( \\tau , X ( \\tau ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> X ( t _ { n } ) = { \\bar { T } } _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( \\beta ) } \\sum _ { f = 0 } ^ { n - 1 } \\int _ { f _ { r } } ^ { f _ { r , n } } ( t _ { n } - r ) { \\cal { C } } ( \\tau , X ( \\tau ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(my_image.shape)\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1100\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xl(image=np.array(my_image))['image']#[:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d20180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 1950, 3)\n",
      "(188, 1950, 3)\n",
      "(96, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAEYCAAAAAChfno9AAAMv0lEQVR4nO3be3xU5Z3H8c+ZSUJCEkKIhAQhE+4hCWE0JaCBFRavLAsIIiouZKFaLkvFqvVSuxjtKoraFoNCRVC3F4pQsYjFioBXKJcFLYhbqNwERFFRUJBLnv3jnDMzmTnBWM6+Usv3/c8883ue8ztP5sx5znOeMwERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERERH5B7H6ssN+pvttv6/8TAdAr8orfM95xsh4HJPde3BZiU/5alINeYNbXuxTOoBVPQt2+pjujFM0H0y/jj5lC+5cBeaOiT6lA3q9znUz/Et3xmm7F256wseECy9v95mP6Ri8Mt2E/Ex4ZrF2FczJ3d3Mt3zXs6791T/0LR3A9KnG13xnltQHp91PteVbvv+4upLxTX1LB0DmGn/zyd+Zhb9p7B74wb+T6BvImX483R7/vrB+su308z2elA6AdZg3Zp9+OnJmfJkBRwMptUeSpr3tQ8IzzlemVSgUCoUKrjbTfEj3hLmoMBQKhc6+9MRBH9LBXtM5FAqFQl3GmTt8SfitsOSSjfVVrR71dL2bvXj76r7xsWbm905pwgOn2y2Az444hZYH/UgHZoVTuOEMOsCzAoZzwnn5iTXNqvIP061PTnuPrZb3xzRJiA41w+xCxqN+dK2pec4pveVHOhhq3DUTP0aYvxdNczsFklPPT4h3JZ+iXIt2L1FibuoRW9Wd1vxTU4pNDZiB58ZWtQyEySfb0G63x76WGHvOa42x3w9/t1Nio4UfjgGsPdCRghQ6WEGAP3qk+1dTYRcmuZGf1aYnNlv61zGA9TL0CnShaW5WEpCyxCPhGpNsFyKLY08c8mj212OZwMBxUBwsJy07G6BflUfLRNap5z+etac5ZVo7BTyOxgAD08s5ewdMfrju/rqYAEO7AqbZ+N/FbWY6cdZKzMCPbvba1+GX674/mpzQ5O5bOA/4A9DJbIA9DwUBeM8j3cr4pe0Uj7vYKXemlgMfAteaaquJqQoANKvxSHhwY1wg70Bio5PktIOWC4CrzUSa2+OSNbWDR8J4rXcduiQx2nyt/Tdam9/7RUKltXTD616p+l3egP0BlB1nSYpH/GiX5g/AJ5mT2ZHnhB50XneHMl6xUss4br3privf0Mp+nbiMHQB/8FpwtnqZIbFvMYlfTpMBkLsa4B4TutUdIG6+xt7mtZi2wchV3Un4vcSjlmQf8+kXAhw9ROQrtt95vSWmcSczoG7CIR7rbnbCnZkABwzL3TPsWGLThJPPkPpRNNq1EoDsecY+wIt7cLJ5dBv7j6n6Bf9Tt1cApJtxHvvzZC6+MVK+pqqqqurfALh/xipg/qK5LHBrFzu9vvHdzcCipzL5pVv1cFs324AwkGUy7bcXVlVVVV0fdJs9ZtIi+xqzetec+L6kbjGvlAJPj7KT7ezt1vT/MwCBOh9jX9M35t28N0/0iU8YXHN8RUfgQD5AB7M18vnNnGK/1ll7nltnCPj9iiPnxScs3vfZMsC54+totkRqjicORzet3WqA0qqqqqrrMsAibf14q5e53hQD9BjotDPuB/TjdRSZQpMDwHI3ze6KhMwcuWcc963stSmxJsHUT6Pl8oqKigr7gmuZ1nXblZSs7F7Sxu5QXp0aq6zr3BElBQDsmA9YXXBadK6oqKg4P/pF3hX5BIc9z8pwnTT3VUKPrWCCnLQjS0xbgOG3Y584mSWlpn1p9DvC7JgD8tIlmKw6CU0GdNtK7lb3tMPY19TRVVC4FgiVFL5RUhyzycEvouVlvYkb8k82hSd+SIut9HnFSfi5/WeF4DcJY+bYJ/n+XUBeRUVFxXkpAM9tWAN71p8FFJeMuK+ks53FOcC3/u5oCw7vDQJ5JXk7i0otgAGvxSeGq3hsnJVupoxPrEowdwLQq3QwQLdwOBzuDkDr+OvZIzXb762xp0cmADHjT9KcRzbOrhkPYH3Sps5G7cPhcLg8eoD3neOWPinGZECf/CFOIL0TMGgu3XLhKAD39zd/BgIlYB+i0poZJ6bPbBvJxk9/HSlmGYoNUNHiKifSLQRctpDKJu4BXldkJgNJJUD7tcCEmofX10yP6e+BHtG+nqRwPxYX4V5dO+cDu5taPVOpfBWAnUXmexa0aw/8NuEAmxS2FQG54XA4XO5cB02l05mf18x/tuZuOxYZ4lb8t1M7tGba9kdmBoF/8Vg9TTa9np3WakjDHm1u6QaLh4/fD3B7dXV19Y8BGP4CXLEvHNvSGaLp9Dk8NHJ7bF10iAbG9ozEr62urq6+P8l9+/RTkRrTco4JsaP3k0udQFMDvHYhVy6HN68C7r2Pn5owWCfT4VJ7canuEF15IloOH+D9Wc04eOmzz9st7WF0excWjYbjecDGEj4yFgSON4G5/2lvV2eIfipmpbLHVxx7qWXW4ZwjlU6kay1ggtYLg2hrAHYUc+wIzoXepFEciE2WadJ6myygsrq6unpqFlhFYKh8w91DzBCdBTSDtf/cJDKg2kN06G0C9oy1yALLPq0C55z/7LScXw2jAZaaTSnX/IoHf1A3PNocK4P1pbExp2MjjRnEjTw2cfJDI6qcqtmF9usq8yir+Njj9gdgxF+i5Z17Rpixc0axqeyZTZs2f2DBIeB/LR4ZAgXLSN9gevAjY7IJGmDyBAACseNKMPZNmlk93bT79VAOp67ZtHnzu3DxLGAbfJgCM/sQ2mtgp/nUgtoAvOeM9L+MpggMq3M7Ydbda5qabAwbNm3a/BwMqQEMHAH2NqHHoRNBa4t5H8pWAMcJxw16K9bPj4vse+ngSH50m/PO/fXIQrPUMlfCtE83LOLOm9zG9u39JnPAdN2xAvIN97yZYTJfXALQce+jmAz49wY9/vr5d+OvNo6NpZ5hAA6SbPp6PbzPzV9F2+1TPo6PW5knnHlImjttf6dtdmTHRYsBA3vKkyDmUkjwHeB9jx2ZAqfQKhJa2ybZTWi9HAbLkHIkF4idjWS+C2whnkWt06/MjOg+GOeumDGvP7CApC/K4ILY55RTR2JVXg4b4lMOSphG1qd7m1NW2+NMcj5FsBEgr0NXCu0ONkDG67fVelbUf4ADtTB4rnfd0LeG8sGwlvFhy7gXs97u/K3DilGR78GTLZLKz1oIfxoAWDHn0tjvwJ887uTeG+uWJkdiXVZET6OjQc5PnUPBO1lA9gvRDe8sJznx+EKkf5dHF3Z+sHzGT9zyAfLz/6sTKW9kAiO/G91wWzK9b4bmCfPoBQmz8HpY556yOnYh6oG02JpBXRq2gyZrPcPr29e3jLKr54DvP9Ounsp7J7EnMfrBdW7prdxIcIBzc52e9CXWpEgLolez1ofAqvNH2Wa+6pbG3hoTHu0ssRTxDEwaGYlHTsqUzI9SPFeHtkUav1oWE15VZL92PmsRyYt7ReKRJ9FteBs8ltDgyonzvMKNIHn3X7zCOX0vqG+Li/r2J3GBE4CDgQ1JA0cnhB9352h0ORkJlrzvrjz0DcZv4Lgg8f4SoDL6k8ovo0M05dudSWeOx5KRsyfvHwnMft4tdY8d9u7Y5iysNu+Nt4xL69tTY2mU58EX/fF1Z7+B846c/u8wkr/Y6kw3j/Wj1YennY+Bi9c6M/SM7o3zCfmnMbqfvCxm4fhYQ9dR6zejMFoOXnXwtPPxYswtV3Y9Y5PImayzu65/jQ/J0p2JVf+76rs0fkNjnHns8IfP9ifhGcj5bcC8k6du1hAB7LWU3FcwHjPsv0ULAFrdlv25P/kaUeNMIdL23lyaCumjgid86MDeO5PD0GQMfNLigVtWz3ryNPMVbi+Y0BxOTMraetn6fW9f3MbjPk9O7YTzK55ggxZfvsa25gAE+KwdV+w/ddsGcTuV8x3Dc778aKzxJH19k/8HmcGvZqVhMhq0Qv61Ohy64VzLpI54vrD/zgk+THp7ruZn2ZY5Oebjj2HQt/w2qXGUuT8ceNE8dcqGDZHvPINqb740GO+lkG/kduchY8GexQPbNOQxusS7y/23rkAgcMqGXy/A3e5z5UDA8mVOETmmgfpW1L5FTvfz/Zv2uW6/+3i6ttb7yUbD1S7Y4z64qa01DXugckrN37o2ktuHOb6IiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIj8w/k/639Y/wQFzloAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=480x280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> Y _ { q } = Y _ { l } ^ { 2 T } + Y _ { 2 p } ^ { D } = \\prod _ { j = 1 } ^ { D } d _ { q - j } f ( X _ { j } ) : \\sum _ { j \\neq Z r } ^ { D } d _ { q - j , f } ( X _ { j } ) + \\sum _ { j = 0 } ^ { q } d _ { q - j l } ( X _ { j } ) , \\quad q = 3 r + 1 , 2 . . . <E> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> Y _ { q } = Y _ { l } ^ { 2 T } + Y _ { 2 p } ^ { D } = \\prod _ { j = 1 } ^ { D } d _ { q - j } f ( X _ { j } ) : \\sum _ { j \\neq Z r } ^ { D } d _ { q - j , f } ( X _ { j } ) + \\sum _ { j = 0 } ^ { q } d _ { q - j l } ( X _ { j } ) , \\quad q = 3 r + 1 , 2 . . . <E> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(my_image.shape)\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xl(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21bd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddffea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32849605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526fe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e1197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00848f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbb5059",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data_Module' object has no attribute 'data_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DISREGARD this uses wrong transformations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get image and label from train data -- change number for different ones\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_tensor, label \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_train\u001b[49m[\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m transform(image_tensor)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data_Module' object has no attribute 'data_train'"
     ]
    }
   ],
   "source": [
    "# DISREGARD this uses wrong transformations\n",
    "\n",
    "# Get image and label from train data -- change number for different ones\n",
    "image_tensor, label = dataset.data_train[12]\n",
    "transform = transforms.ToPILImage()\n",
    "image = transform(image_tensor)\n",
    "\n",
    "print('\\nOriginal image and formula:')\n",
    "display(image)\n",
    "print(token_to_strings(label))\n",
    "print('\\nPredicted formula: \\n')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    prediction =  model.predict(image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(prediction),'\\n')\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# My first app\n",
    "Here's our first attempt at using data to create a table:\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "  'first column': [1, 2, 3, 4],\n",
    "  'second column': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame(\n",
    "    np.random.randn(10, 20),\n",
    "    columns=('col %d' % i for i in range(20)))\n",
    "\n",
    "st.dataframe(dataframe.style.highlight_max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba747",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = pd.DataFrame(\n",
    "    np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4],\n",
    "    columns=['lat', 'lon'])\n",
    "\n",
    "st.map(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db861789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "x = st.slider('x')  # 👈 this is a widget\n",
    "st.write(x, 'squared is', x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(float(.6)*420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b0a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
