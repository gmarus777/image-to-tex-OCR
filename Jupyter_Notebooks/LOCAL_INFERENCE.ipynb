{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afce2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07ea162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "from Data.image_transforms import Image_Transforms\n",
    "\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb68b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb165d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmin_h: 9\\nmax_h: 177\\nmin_w: 24\\nmax_w: 512\\nmin_ratio: 0.42857142857142855\\nmax_ratio: 35.357142857142854\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")\n",
    "'''\n",
    "min_h: 9\n",
    "max_h: 177\n",
    "min_w: 24\n",
    "max_w: 512\n",
    "min_ratio: 0.42857142857142855\n",
    "max_ratio: 35.357142857142854\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6c15cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ResNetTransformer(dataset=dataset).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4390ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Printed1_2D600_350_xs.pth\"), map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab21e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab200a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427cc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "# Helper Function to convert prediction labels to strings\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s\n",
    "def findPositions(image):\n",
    "    positions = np.nonzero(image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 0), 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ccebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa947fc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n"
     ]
    }
   ],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_medium(image=np.array(image))['image'][:1]\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5acbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 516, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\mathrm { P e r m } \\left( S \\right) \\subseteq \\mathrm { S } _ { \\eta _ { \\nu } } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\mathrm { P e r m } \\left( S \\right) \\subseteq \\mathrm { S } _ { \\eta _ { \\nu } } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    pass\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7f98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 658, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> { \\cal D } ( X \\equiv x _ { i } ) \\equiv \\sum _ { j = 1 } ^ { L } p \\{ X \\equiv { \\cal x } _ { i } , Y \\equiv g _ { j } \\} <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> { \\cal D } ( X \\equiv x _ { i } ) \\equiv \\sum _ { j = 1 } ^ { L } p \\{ X \\equiv { \\cal x } _ { i } , Y \\equiv g _ { j } \\} <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d149d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old 152 658\n",
      "(17, 8) (620, 132)\n",
      "new 152 658\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> { \\cal D } ( X \\equiv x _ { i } ) \\equiv \\sum _ { j = 1 } ^ { L } p \\{ X \\equiv { \\cal x } _ { i } , Y \\equiv g _ { j } \\} <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> { \\cal D } ( X \\equiv x _ { i } ) \\equiv \\sum _ { j = 1 } ^ { L } p \\{ X \\equiv { \\cal x } _ { i } , Y \\equiv g _ { j } \\} <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "print('old',h,w)\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left-1, top-1), (right+1, bottom+1), (0,0,0), 0)\n",
    "\n",
    "print( (left, top), (right, bottom), )    \n",
    "\n",
    "#Thresholding\n",
    "ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "print('new',h,w)\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "#print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c580c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2303370786516854\n",
      "(41, 178, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> h ( a , \\, b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { m } } \\eta ^ { n } , <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> h ( a , \\, b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { m } } \\eta ^ { n } , <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "positions = np.nonzero(my_image)\n",
    "top = positions[0].min()\n",
    "bottom = positions[0].max()\n",
    "left = positions[1].min()\n",
    "right = positions[1].max()\n",
    "\n",
    "my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_small(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc374a31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 57, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "my_image = Image.open(my_image_path)#.convert(\"L\") \n",
    "my_image= np.asarray(my_image)\n",
    "#my_image = cv2.imread(my_image_path)\n",
    "#my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_small(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a264888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 1080, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> P \\left( \\frac { \\widehat { \\partial } v } { \\partial } \\epsilon } + { \\bf V } \\cdot \\nabla { \\bf V } \\right) \\Xi \\Psi \\, \\leftrightarrow \\, \\psi \\, \\tau \\, T } \\, \\epsilon \\, f \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\,\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> P \\left( \\frac { \\widehat { \\partial } v } { \\partial } \\epsilon } + { \\bf V } \\cdot \\nabla { \\bf V } \\right) \\Xi \\Psi \\, \\leftrightarrow \\, \\psi \\, \\tau \\, T } \\, \\epsilon \\, f \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\,$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8208dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1404494382022472\n",
      "(140, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> X ( t _ { n } ) = T _ { m - 1 } \\{ X ; t _ { 0 } \\} ( t _ { n } ) + \\frac { 1 } { \\Gamma ( { \\cal P } ) } \\sum _ { r = 0 } ^ { t _ { r } < 1 } ( t _ { n } - \\tau ) g ^ { g . 1 } F ( \\tau ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> X ( t _ { n } ) = T _ { m - 1 } \\{ X ; t _ { 0 } \\} ( t _ { n } ) + \\frac { 1 } { \\Gamma ( { \\cal P } ) } \\sum _ { r = 0 } ^ { t _ { r } < 1 } ( t _ { n } - \\tau ) g ^ { g . 1 } F ( \\tau ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "584d011a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 1774, 3)\n",
      "(136, 1200, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\chi ( q _ { n } ) \\, \\sum _ { < } f _ { m - 1 } \\{ \\chi _ { z } t \\} \\{ \\epsilon _ { n } \\} } & { = 0 } ^ { n - 1 } \\int _ { \\ell \\nu } ^ { \\ell _ { r } ! } \\{ t _ { n } - \\tau \\} \\oint _ { \\bot } P \\{ \\epsilon , X ( \\varphi ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\chi ( q _ { n } ) \\, \\sum _ { < } f _ { m - 1 } \\{ \\chi _ { z } t \\} \\{ \\epsilon _ { n } \\} } & { = 0 } ^ { n - 1 } \\int _ { \\ell \\nu } ^ { \\ell _ { r } ! } \\{ t _ { n } - \\tau \\} \\oint _ { \\bot } P \\{ \\epsilon , X ( \\varphi ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "#my_image = Image.open(my_image_path)#.convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(my_image.shape)\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1200\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "859b5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 1950, 3)\n",
      "(96, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> V _ { q } = V _ { l } ^ { \\nu } \\cdot V _ { 2 \\nu } ^ { q } v \\, v _ { y } ^ { q } = \\sum _ { j = 1 } ^ { p } d _ { q - j l } ( \\chi _ { j } ) \\cdot \\sum _ { j \\neq l } ^ { \\infty } d _ { q \\tau f } \\delta ( X ) + \\sum _ { f y s } d _ { \\sigma \\tau } f _ { j , \\nu } \\; \\; \\; q = 3 r + 1 , y r . <E> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> V _ { q } = V _ { l } ^ { \\nu } \\cdot V _ { 2 \\nu } ^ { q } v \\, v _ { y } ^ { q } = \\sum _ { j = 1 } ^ { p } d _ { q - j l } ( \\chi _ { j } ) \\cdot \\sum _ { j \\neq l } ^ { \\infty } d _ { q \\tau f } \\delta ( X ) + \\sum _ { f y s } d _ { \\sigma \\tau } f _ { j , \\nu } \\; \\; \\; q = 3 r + 1 , y r . <E> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09bd905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f8af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32c5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad0486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d878f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fbb5059",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data_Module' object has no attribute 'data_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DISREGARD this uses wrong transformations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get image and label from train data -- change number for different ones\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_tensor, label \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_train\u001b[49m[\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m transform(image_tensor)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data_Module' object has no attribute 'data_train'"
     ]
    }
   ],
   "source": [
    "# DISREGARD this uses wrong transformations\n",
    "\n",
    "# Get image and label from train data -- change number for different ones\n",
    "image_tensor, label = dataset.data_train[12]\n",
    "transform = transforms.ToPILImage()\n",
    "image = transform(image_tensor)\n",
    "\n",
    "print('\\nOriginal image and formula:')\n",
    "display(image)\n",
    "print(token_to_strings(label))\n",
    "print('\\nPredicted formula: \\n')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    prediction =  model.predict(image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(prediction),'\\n')\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d738f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39597f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db861789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf6bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb316f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
