{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afce2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07ea162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb68b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb165d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmin_h: 9\\nmax_h: 177\\nmin_w: 24\\nmax_w: 512\\nmin_ratio: 0.42857142857142855\\nmax_ratio: 35.357142857142854\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")\n",
    "'''\n",
    "min_h: 9\n",
    "max_h: 177\n",
    "min_w: 24\n",
    "max_w: 512\n",
    "min_ratio: 0.42857142857142855\n",
    "max_ratio: 35.357142857142854\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6c15cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ResNetTransformer(dataset=dataset).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4390ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Printed4_nocompression.pth\"), map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab200a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LitModel  = LitResNetTransformer(model=model)\n",
    "#model = LitModel.load_from_checkpoint(\"Models_Parameters_Log/Printed2_inverted.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427cc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "# Helper Function to convert prediction labels to strings\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ccebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose([\n",
       "  LongestMaxSize(always_apply=True, p=1, max_size=420, interpolation=2),\n",
       "  PadIfNeeded(always_apply=True, p=1.0, min_height=420, min_width=420, pad_height_divisor=None, pad_width_divisor=None, border_mode=0, value=0, mask_value=None),\n",
       "  CenterCrop(always_apply=True, p=1.0, height=250, width=420),\n",
       "  ToGray(always_apply=True, p=0.5),\n",
       "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
       "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_transform_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbe614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f89dc9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 424, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> n : = \\mathrm { d e g } ( f \\, ) \\, = \\, q ^ { 3 } + 1 . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> n : = \\mathrm { d e g } ( f \\, ) \\, = \\, q ^ { 3 } + 1 . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/my_image.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "\n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    \n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5acbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 516, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\mathrm { P e r m } ( S ) \\cong { \\bf S } _ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\mathrm { P e r m } ( S ) \\cong { \\bf S } _ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    pass\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7f98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 658, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\qquad p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\qquad p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06e44b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23100303951367782\n",
      "(152, 658, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\qquad p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\qquad p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "#Thresholding\n",
    "ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c580c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2303370786516854\n",
      "(41, 178, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> h ( a , b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { n } } \\eta ^ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> h ( a , b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { n } } \\eta ^ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc374a31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 57, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAD6CAAAAADL1GzaAAAFk0lEQVR4nO3ay29UZRjH8eecM5d2pnNpS69AW+iFtkDBFBAIRQ1CouLKqBt37vxT3Ll35dKQmKhxoQSMGiUWUGipgNA2tNDLtHPpzLSd2zkueplpizBNOsy8ne9nMznvnJ48yW/ea48IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKCMaMUuYJv0YheAl1PtR7UzPJ16sLd+cKjYdeTJVuwCXgXdsExTdMtaa/CesobPv6Y/iWWKWVbedv9wp4nUdrdWieZxrrfZvNr00OOaHlcR69qG3d+TLMPf2aqP35WG0PLKb9KyFh/NPmmPJLJdq7Tt/pCkqW+P70DjfHxPMmjYxBLNWg5dD1st7bduqTHalcPCoanL0Jt9iYnxBb3SYYkYycC8SNtp3407xS4tT2XQk+Yi6UzmzCfOq/Yej9O0xLEYFekeGP/RtW82Wezi8lIGIaVSIjIVXk6lpkOGJWIkZz19bx+eaw2MBgmplGSGA0bm6dpV3ZE2vcv/+0MWDiVE9/rmAjmJxP6asVUujj1ToyOVw8JBRBwd1aGZYDYl3WFYurlsFrGk7SiPnqRVGbPzOddmUkRTZZdULiFlAlp4Q4MqfaisaOUxrBeftuEjr3tfejapxtGlUr8wtzOVSOU5k+hOpy2zmBCj0mXXnv83xnIotYPVFY5Sc9LZQxMjY+mX36dZIs6+/saZn+9J7Zk3Oiqeu9TWam98MbbTJRaESiHVvjtwLfAkj5AskbrTh0zf/oWpYB63lzyFQtIPHu++nedgV9n7cfzzug/aT92cu/rHC4a7HSyvgFQJSbOk670ue5Urv0n0wmXHb4+XIi3Hx+fi8RfcpyuxFldjeSNiiXQcMyd1T14Fuy9fGvxavAl3vWNDu6br2obFkhIZKdOTxNNeNVJTU+HOpye5+9qth0GxV3kXjNx2x7nDmT9vOvfNRgtUZIEoE1LLhac/uAZcnmxImrZhi2pZ6+c8HRd9j+dFGltcSxvWDfUHj2qRR/6GKCEVRk3v1L3X05U5c5LhdBjZFYGWSSYyq5fN/bbJSqezpdUezd0ItbXeH/XJiUxEjd1RliIh2fc2jw6Fp+J+73pImrfBX5l9ScFIhGbCq5ct/dFo64B24tCDsVjOQ/T4+FzVwLkHI7mNKlAkJP87ju+HxEw4sz1J8+xv8mT7hD0+tRxdDam6bklr9ho9jYOjuQPbk6dpiZl7H868qqp3iiIhtbzvjtU0nN9XW7EekhUZCzjN9fHOSMbWOlJVs+P+dwlPnaFPD0dyHpJOi0gooMjmKIcSIemeLm/92R5fZ011Tkjh8PPvttd607d/Eu/J+dnR4JZvF+5MF6rMgin9kDRLzEv9VyZDseqjF9+ozrbXNvoqcuakZGR65QzI5pZwSKTiWMXgv5sfZvO6w6rNSCqEZIk0HnNcmRSR8YYBf3Yz62pqzJ2TFqeiKwOZmYjFEiId5zPfbHmxzl4j05HNjSWv5EPSTak+PvdgSUQkGtXt2Y1PZGy+IndOioRWzg8SgbgzI9LSOXRt6yG3GZp/0TFRaSr5kMzq3ouHU786RVwHjx5xtH10PRA1RUSsWHJ2wz4plVw95FmYCDR2H+i+fXVMNh+tpiNJxTayIgqEJN2fveVKxq4/k/1vnjuZ2fOp/9vlhIiIZFY/12RfLBm91/Bh7/SXt0Q2H3+n1VvaiQohBX6ZMJPDQZGFf5b+1vXUSGTtVPR/X/e5+5VDn5kcXNz6jTpvCClF2/RZjlT5V8V2QirnPAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgl/kPgAS5/kHxWQYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\qquad A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\qquad A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xs(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f128d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 1080, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=420x250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\rho \\left( \\frac { \\partial \\cdot } { \\partial t } + V \\cdot \\nabla V \\right) = - \\nabla p + \\nabla \\cdot T + f <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\rho \\left( \\frac { \\partial \\cdot } { \\partial t } + V \\cdot \\nabla V \\right) = - \\nabla p + \\nabla \\cdot T + f <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "628056a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1404494382022472\n",
      "(140, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=470x280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> X ( t _ { n } ) = T _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( \\beta ) } \\sum _ { r = 0 } ^ { n - 1 } \\int _ { t _ { r } } ^ { t _ { r . . . 1 } } ( t _ { n } - r ) ^ { g - 1 } F ( r , X ( r ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> X ( t _ { n } ) = T _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( \\beta ) } \\sum _ { r = 0 } ^ { n - 1 } \\int _ { t _ { r } } ^ { t _ { r . . . 1 } } ( t _ { n } - r ) ^ { g - 1 } F ( r , X ( r ) ) d \\tau . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xl(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b320d5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 1774, 3)\n",
      "(136, 1200, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=470x280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> X ( t _ { \\alpha } ) = T _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( { \\cal B } ) } \\sum _ { r = 0 } ^ { r - 1 } \\int _ { \\ell _ { r } } ^ { r _ { - 1 } } ( t _ { R } - \\tau ) ^ { \\beta - 1 } P ( \\tau , \\chi ( \\tau ) ) d \\Upsilon . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> X ( t _ { \\alpha } ) = T _ { m - 1 } [ X ; t _ { 0 } ] ( t _ { n } ) + \\frac { 1 } { \\Gamma ( { \\cal B } ) } \\sum _ { r = 0 } ^ { r - 1 } \\int _ { \\ell _ { r } } ^ { r _ { - 1 } } ( t _ { R } - \\tau ) ^ { \\beta - 1 } P ( \\tau , \\chi ( \\tau ) ) d \\Upsilon . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(my_image.shape)\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1200\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xl(image=np.array(my_image))['image']#[:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06eee1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 1950, 3)\n",
      "(115, 1200, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=470x280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> Y _ { q } = Y _ { 1 } ^ { 2 T } + Y _ { 2 q } ^ { ( q } = \\sum _ { j = 1 } ^ { 2 p } d _ { q - j f } f ( X _ { j } ) \\times \\sum _ { j = r } ^ { 3 T } d _ { q - j } f ( X _ { j } ) \\times \\sum _ { j = p } ^ { q } d _ { q - j } f ( X _ { j } ) , \\quad q = 3 r + 1 , y r . <E> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> Y _ { q } = Y _ { 1 } ^ { 2 T } + Y _ { 2 q } ^ { ( q } = \\sum _ { j = 1 } ^ { 2 p } d _ { q - j f } f ( X _ { j } ) \\times \\sum _ { j = r } ^ { 3 T } d _ { q - j } f ( X _ { j } ) \\times \\sum _ { j = p } ^ { q } d _ { q - j } f ( X _ { j } ) , \\quad q = 3 r + 1 , y r . <E> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1200\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xl(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe9a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf5728d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9f7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f932522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bc99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382c63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbb5059",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data_Module' object has no attribute 'data_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DISREGARD this uses wrong transformations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get image and label from train data -- change number for different ones\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_tensor, label \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_train\u001b[49m[\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m transform(image_tensor)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data_Module' object has no attribute 'data_train'"
     ]
    }
   ],
   "source": [
    "# DISREGARD this uses wrong transformations\n",
    "\n",
    "# Get image and label from train data -- change number for different ones\n",
    "image_tensor, label = dataset.data_train[12]\n",
    "transform = transforms.ToPILImage()\n",
    "image = transform(image_tensor)\n",
    "\n",
    "print('\\nOriginal image and formula:')\n",
    "display(image)\n",
    "print(token_to_strings(label))\n",
    "print('\\nPredicted formula: \\n')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    prediction =  model.predict(image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(prediction),'\\n')\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# My first app\n",
    "Here's our first attempt at using data to create a table:\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "  'first column': [1, 2, 3, 4],\n",
    "  'second column': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame(\n",
    "    np.random.randn(10, 20),\n",
    "    columns=('col %d' % i for i in range(20)))\n",
    "\n",
    "st.dataframe(dataframe.style.highlight_max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba747",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = pd.DataFrame(\n",
    "    np.random.randn(1000, 2) / [50, 50] + [37.76, -122.4],\n",
    "    columns=['lat', 'lon'])\n",
    "\n",
    "st.map(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db861789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "x = st.slider('x')  #  this is a widget\n",
    "st.write(x, 'squared is', x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(float(.6)*420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b0b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
