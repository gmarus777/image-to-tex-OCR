{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5115f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1104e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "from Data.image_transforms import Image_Transforms\n",
    "import cv2\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5ed0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c95ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b23360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s\n",
    "def findPositions(image):\n",
    "    positions = np.nonzero(image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "    image = cv2.rectangle(image, (left-2, top-2), (right+2, bottom+2), (0, 0, 0), 0)\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0d9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with lightining\n",
    "#model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "#lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "\n",
    "#lit_model = lit_model.load_from_checkpoint(\"Models_Parameters_Log/epoch=4-step=17280.ckpt\")\n",
    "#scripted = lit_model.to_torchscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe3260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torch/jit/_recursive.py:262: UserWarning: 'batch_first' was found in ScriptModule constants, but was not actually set in __init__. Consider removing it.\n",
      "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n"
     ]
    }
   ],
   "source": [
    "# Load with pytorch epoch=4-step=17280.ckpt\n",
    "\n",
    "model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Printed2_2D600_350_pre.pth\"), map_location=torch.device('cpu')))\n",
    "lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "scripted = lit_model.to_torchscript()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4453f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_SIZE = 1800\n",
    "BINARY_THREHOLD = 180\n",
    "\n",
    "def process_image_for_ocr(file_path):\n",
    "    # TODO : Implement using opencv\n",
    "    temp_filename = set_image_dpi(file_path)\n",
    "    im_new = remove_noise_and_smooth(temp_filename)\n",
    "    return im_new\n",
    "\n",
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    length_x, width_y = im.size\n",
    "    factor = max(1, int(IMAGE_SIZE / length_x))\n",
    "    size = factor * length_x, factor * width_y\n",
    "    # size = (1800, 1800)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    temp_filename = temp_file.name\n",
    "    im_resized.save(temp_filename, dpi=(300, 300))\n",
    "    return temp_filename\n",
    "\n",
    "def image_smoothening(img):\n",
    "    ret1, th1 = cv2.threshold(img, BINARY_THREHOLD, 255, cv2.THRESH_BINARY)\n",
    "    ret2, th2 = cv2.threshold(th1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    blur = cv2.GaussianBlur(th2, (1, 1), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4736dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/ipykernel_25880/3931525972.py:19: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1120x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "MAX_RATIO = 35\n",
    "\n",
    "# Resize images with roughly the same aspect ratio\n",
    "# Resize height to 32 times the original, and width with roughly the same ratio but it must be divisible by 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40d863c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/ipykernel_25880/793948986.py:11: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1120x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a6fa632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/60y8v25x3ns_jgsx6clbdb180000gn/T/ipykernel_25880/1307951978.py:11: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=1120x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47fde1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\qquad \\mathrm { P e r m } ( S ) \\simeq { \\bf S } _ { n } . \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\qquad \\mathrm { P e r m } ( S ) \\simeq { \\bf S } _ { n } . \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 200:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 200\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8b4718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 658 0.23100303951367782\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\qquad \\qquad \\qquad \\qquad \\qquad P ( X = x _ { i } ) = \\sum _ { y = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) \\qquad \\qquad \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\qquad \\qquad \\qquad \\qquad \\qquad P ( X = x _ { i } ) = \\sum _ { y = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) \\qquad \\qquad \\qquad \\qquad \\qquad <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "\n",
    "aspect = h / w\n",
    "print(h,w, aspect)\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 300\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 400\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "961d0cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\begin{array} { c c c c c c c c c } { A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & {\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\begin{array} { c c c c c c c c c } { A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & {$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 100\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xss(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "\n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afff02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 500\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "       \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c813a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 500\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "#image_tensor = Image_Transforms.test_transform_with_padding_medium(image=np.array(image))['image'][:1]    \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06177be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c26385",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e685d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817e138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
