{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf971c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a95696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "from Data.image_transforms import Image_Transforms\n",
    "import cv2\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1d3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564893de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a2be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s\n",
    "def findPositions(image):\n",
    "    positions = np.nonzero(image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "    image = cv2.rectangle(image, (left-2, top-2), (right+2, bottom+2), (0, 0, 0), 0)\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a211d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with lightining\n",
    "#model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "#lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "\n",
    "#lit_model = lit_model.load_from_checkpoint(\"Models_Parameters_Log/epoch=4-step=17280.ckpt\")\n",
    "#scripted = lit_model.to_torchscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5c64bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with pytorch epoch=4-step=17280.ckpt\n",
    "\n",
    "model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Collate1.pth\"), map_location=torch.device('cpu')))\n",
    "lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "lit_model.freeze()\n",
    "scripted = lit_model.to_torchscript()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e136c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIZE = 1920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d376c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 116, 516])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=516x116>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\tag { } { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } \\\\ { \\bf F } { \\bf J } { \\bf J } { \\bf J } { \\bf J } }\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\tag { } { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } & { } \\\\ { \\bf F } { \\bf J } { \\bf J } { \\bf J } { \\bf J } }$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "h, w, c = image.shape\n",
    "\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c0c756d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=658x152>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1, 152, 658])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=658x152>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\begin{array} { c c c c c c c c c } { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { { \\displaystyle { { \\displaystyle } } } } } } } } } } & { { { \\bf { { { { \\bf { { { { \\bf { { { { { { { \\bf { { { { \\bf { { { { { { { { { { { { { { { {\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\begin{array} { c c c c c c c c c } { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { \\displaystyle { { \\displaystyle { { \\displaystyle } } } } } } } } } } & { { { \\bf { { { { \\bf { { { { \\bf { { { { { { { \\bf { { { { \\bf { { { { { { { { { { { { { { { {$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "print(display(transform(image)))\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1b75916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAIAAAA+3HCUAAADMklEQVR4nNVWXyhzYRh/zmfWppWtk5qMSFMuFKlFIo3UolxZbiilcynLSpEbCnODFJ0si1pJKXdKu1JO/sQYOdyd0rnwZ05eYTvTeb+Lfc35tvOdtPUZv7v3+fN7f+/T87zvS2CM4YfgV7YFKINlWYRQkvE7ap2bm3t4eOjq6uI4Tm7PjtZAIBAMBgGA5/lUL8a4qqqqoaHh4OBAbtd8kToZNjc3EULb29tarRYhZDQaRVFMeI1Go8vlEkWRZVmXyyVPJL5+tiKRiE6nQwgNDg6urKyEQqG7u7uEt6mpKTc3d3Fx0el0IoTKy8s/MnGWIEkSTdOKrrGxMYfD0dnZubOzI7dnoa5xnJ+fi6JYW1ub6uJ5PhqNAoDFYtFqtQl7Fvo1jnA43NjYqOgqKipStGetrmngO96v/4JyD/T397e1tTmdzsw3YBhma2srFotNTU3pdDqPx7O2tvb59I6ODo/H82eROoYMwxAEMT8/n/mw7+7utra2xmKx4eHh5eXlDNmSe0CSpIWFhcLCQvmdlx5eXl56e3vHx8c1Go3JZEp6hNJAslav19vT01NSUnJ/f58h9erqqsFgqK+vBwCO4+SPkxzRaNTtdg8NDQHA/v6+CuFf/SoIwuHhIUVRNE3f3t6mRguCIAiCIhFJkvn5+XKLz+erqak5Pj4GAIZh2tvbFRP39vbcbjfP8z6fT/G6VdY6OTk5MjIS3/jy8jI1mmXZi4sLRaLq6mqbzZZYPj4+npyc1NXVBQIBhFAoFJqenlZMtNvtAGA2m5eWlvr6+lS0fszW6elpcXExRVEURVVUVJSWlmYyB0dHRzk5Oc/Pzxhjv99PkuTr66tKvCRJfr9fnVOTUDwzM3N1dZWXlwcAs7Ozo6OjqQdjGOaTdY1EIhaLxWAwAMDGxsbAwIBer1cp2fX1dVlZmVpREz3g9Xqbm5vjQgGgoKDg7e3t6ekpqQUrKyvNZrMiEUmS8qXVaiUIAgCCwSDHcevr6+o69Hq91WpVjwGe5x0OB0mSdrv9/f0dY0zTtM1mM5lMLS0tZ2dnabcBRVETExPd3d03Nzdpk8jxf/8D4XA4qd6Z4Cf9XX4D60t7gAvI710AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1, 23, 57])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAAAAACU1bgfAAABiklEQVR4nGPUZyATMJGuRWQDmTpr+zQ9SNFZ9YwhFcL6xRR8hIGBgYGROH+qrGc23sBxl4GBIYbtXlKpNwMDAwtxVq7T23DE/XszAwPDE5nd75pIsJOB4dceLwhD9KpSRg/xdjIwMKuqQhgB6gxZSqTYOTFOEFWAaJ0YgIyUAAUwf9ZPfoddwWaTxxx6IU9QBbcKw127c7JNBVaNi7RluM7b4bbza+/UfVg1HrTdLR5yGKsUxJ8Hxde2Y5W+5+rO4HEPyrlx5xrDflQ7551czAPlz5sHZeSFMTAwMFySus2weT00GNd+TL1swQnTyajPwMDwMPpIFR/En5uZoRIiZgwMDDN2Ji3c4CS+GG5RfSMDss5Pv5cwTLiLLX6uNqW4/t4haQLj/2JkRdb5K6jakqGcuQ2LnSsCOBh4FK7AVUvNd0f25yEGSwaGyrBVYQwMDAyv4f5kYGBguMLG8CyvTg+u2sQMkQQZZzac5NcV3HZcW94A7nkEmLicQ34hFm8wEE63k3NxyZCf4gFyTWUW/p+d3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> A = \\theta ^ { \\frac { 1 - 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 } { \\gamma } } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { 2 } } A = \\theta ^ { \\frac { 1 } { 2 } A = A =\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> A = \\theta ^ { \\frac { 1 - 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 } { \\gamma } } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { 2 } } A = \\theta ^ { \\frac { 1 } { 2 } A = A =$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "print(display(transform(image)))\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c04c612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAIAAAA+3HCUAAADMklEQVR4nNVWXyhzYRh/zmfWppWtk5qMSFMuFKlFIo3UolxZbiilcynLSpEbCnODFJ0si1pJKXdKu1JO/sQYOdyd0rnwZ05eYTvTeb+Lfc35tvOdtPUZv7v3+fN7f+/T87zvS2CM4YfgV7YFKINlWYRQkvE7ap2bm3t4eOjq6uI4Tm7PjtZAIBAMBgGA5/lUL8a4qqqqoaHh4OBAbtd8kToZNjc3EULb29tarRYhZDQaRVFMeI1Go8vlEkWRZVmXyyVPJL5+tiKRiE6nQwgNDg6urKyEQqG7u7uEt6mpKTc3d3Fx0el0IoTKy8s/MnGWIEkSTdOKrrGxMYfD0dnZubOzI7dnoa5xnJ+fi6JYW1ub6uJ5PhqNAoDFYtFqtQl7Fvo1jnA43NjYqOgqKipStGetrmngO96v/4JyD/T397e1tTmdzsw3YBhma2srFotNTU3pdDqPx7O2tvb59I6ODo/H82eROoYMwxAEMT8/n/mw7+7utra2xmKx4eHh5eXlDNmSe0CSpIWFhcLCQvmdlx5eXl56e3vHx8c1Go3JZEp6hNJAslav19vT01NSUnJ/f58h9erqqsFgqK+vBwCO4+SPkxzRaNTtdg8NDQHA/v6+CuFf/SoIwuHhIUVRNE3f3t6mRguCIAiCIhFJkvn5+XKLz+erqak5Pj4GAIZh2tvbFRP39vbcbjfP8z6fT/G6VdY6OTk5MjIS3/jy8jI1mmXZi4sLRaLq6mqbzZZYPj4+npyc1NXVBQIBhFAoFJqenlZMtNvtAGA2m5eWlvr6+lS0fszW6elpcXExRVEURVVUVJSWlmYyB0dHRzk5Oc/Pzxhjv99PkuTr66tKvCRJfr9fnVOTUDwzM3N1dZWXlwcAs7Ozo6OjqQdjGOaTdY1EIhaLxWAwAMDGxsbAwIBer1cp2fX1dVlZmVpREz3g9Xqbm5vjQgGgoKDg7e3t6ekpqQUrKyvNZrMiEUmS8qXVaiUIAgCCwSDHcevr6+o69Hq91WpVjwGe5x0OB0mSdrv9/f0dY0zTtM1mM5lMLS0tZ2dnabcBRVETExPd3d03Nzdpk8jxf/8D4XA4qd6Z4Cf9XX4D60t7gAvI710AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1, 23, 57])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAAAAACU1bgfAAABiklEQVR4nGPUZyATMJGuRWQDmTpr+zQ9SNFZ9YwhFcL6xRR8hIGBgYGROH+qrGc23sBxl4GBIYbtXlKpNwMDAwtxVq7T23DE/XszAwPDE5nd75pIsJOB4dceLwhD9KpSRg/xdjIwMKuqQhgB6gxZSqTYOTFOEFWAaJ0YgIyUAAUwf9ZPfoddwWaTxxx6IU9QBbcKw127c7JNBVaNi7RluM7b4bbza+/UfVg1HrTdLR5yGKsUxJ8Hxde2Y5W+5+rO4HEPyrlx5xrDflQ7551czAPlz5sHZeSFMTAwMFySus2weT00GNd+TL1swQnTyajPwMDwMPpIFR/En5uZoRIiZgwMDDN2Ji3c4CS+GG5RfSMDss5Pv5cwTLiLLX6uNqW4/t4haQLj/2JkRdb5K6jakqGcuQ2LnSsCOBh4FK7AVUvNd0f25yEGSwaGyrBVYQwMDAyv4f5kYGBguMLG8CyvTg+u2sQMkQQZZzac5NcV3HZcW94A7nkEmLicQ34hFm8wEE63k3NxyZCf4gFyTWUW/p+d3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> A = \\theta ^ { \\frac { 1 - 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 } { \\gamma } } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { 2 } } A = \\theta ^ { \\frac { 1 } { 2 } A = A =\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> A = \\theta ^ { \\frac { 1 - 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 - \\gamma } { \\gamma } } = \\theta ^ { \\frac { 1 } { \\gamma } } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { \\gamma } } B = \\theta ^ { \\frac { 1 } { 2 } } A = \\theta ^ { \\frac { 1 } { 2 } A = A =$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "print(display(transform(image)))\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7878d77a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_RATIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;241m>\u001b[39m \u001b[43mMAX_RATIO\u001b[49m:\n\u001b[1;32m      8\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m MAX_RATIO\n\u001b[1;32m      9\u001b[0m h_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_RATIO' is not defined"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58230f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 200:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 200\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e499be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "\n",
    "aspect = h / w\n",
    "print(h,w, aspect)\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 300\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 400\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4585246",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 100\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xss(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "\n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 500\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "       \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d508b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 500\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "#image_tensor = Image_Transforms.test_transform_with_padding_medium(image=np.array(image))['image'][:1]    \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f10c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "positions = np.nonzero(image)\n",
    "top = positions[0].min()\n",
    "bottom = positions[0].max()\n",
    "left = positions[1].min()\n",
    "right = positions[1].max()\n",
    "image = cv2.rectangle(image, (left - 2, top - 2), (right + 2, bottom + 2), (0, 0, 0), 0)\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio = (w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.train_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c03662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "positions = np.nonzero(image)\n",
    "top = positions[0].min()\n",
    "bottom = positions[0].max()\n",
    "left = positions[1].min()\n",
    "right = positions[1].max()\n",
    "image = cv2.rectangle(image, (left - 2, top - 2), (right + 2, bottom + 2), (0, 0, 0), 0)\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.train_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c166c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
