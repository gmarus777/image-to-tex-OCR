{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d51f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63af266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "from Data.image_transforms import Image_Transforms\n",
    "import cv2\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873a36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d5bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada01d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RATIO = 15\n",
    "\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s\n",
    "def findPositions(image):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray = 255*(gray < 50).astype(np.uint8)  # To invert the text to white\n",
    "    gray = cv2.morphologyEx(gray, cv2.MORPH_OPEN, np.ones((2, 2), dtype=np.uint8))  # Perform noise filtering\n",
    "    coords = cv2.findNonZero(gray)  # Find all non-zero points (text)\n",
    "    x, y, w, h = cv2.boundingRect(coords)  # Find minimum spanning bounding box\n",
    "    print( x, y, w, h)\n",
    "    # Crop the image - note we do this on the original image\n",
    "    cropped_image = image[y-10:y+h+10, x-10:x+w+10]\n",
    "\n",
    "    return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43ff148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNetTransformer:\n\tsize mismatch for image_positional_encoder.pe: copying a param with shape torch.Size([128, 64, 1600]) from checkpoint, the shape in current model is torch.Size([128, 128, 1920]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load with pytorch epoch=4-step=17280.ckpt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNetTransformer(dataset\u001b[38;5;241m=\u001b[39mdataset)\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModels_Parameters_Log/Printed1_2D64_1600_NORM_WHITE.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m lit_model \u001b[38;5;241m=\u001b[39m LitResNetTransformer(model\u001b[38;5;241m=\u001b[39mmodel, WandB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m scripted \u001b[38;5;241m=\u001b[39m lit_model\u001b[38;5;241m.\u001b[39mto_torchscript()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNetTransformer:\n\tsize mismatch for image_positional_encoder.pe: copying a param with shape torch.Size([128, 64, 1600]) from checkpoint, the shape in current model is torch.Size([128, 128, 1920])."
     ]
    }
   ],
   "source": [
    "# Load with pytorch epoch=4-step=17280.ckpt\n",
    "\n",
    "model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Printed1_2D64_1600_NORM_WHITE.pth\"), map_location=torch.device('cpu')))\n",
    "lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "scripted = lit_model.to_torchscript()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c20fb059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 48 268 37\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=288x57>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(57, 288, 3)\n",
      "torch.Size([1, 128, 1920])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1920x128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scripted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicted formula:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m prediction \u001b[38;5;241m=\u001b[39m  \u001b[43mscripted\u001b[49m(image_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(token_to_strings(prediction))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(display(Math(token_to_strings(prediction))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scripted' is not defined"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = findPositions(image)\n",
    "print(display(transform(image)))\n",
    "print(image.shape)\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fff22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = ~image\n",
    "display(transform(image))\n",
    "image = findPositions(image)\n",
    "image= ~image\n",
    "display(transform(image))\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413faecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7169b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_11.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65207434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_12.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=  \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "findPositions(image)\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94e107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b324c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9425e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae843a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32f0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b39a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
