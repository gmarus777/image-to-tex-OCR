{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf971c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a95696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "from Data.image_transforms import Image_Transforms\n",
    "import cv2\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1d3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564893de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a2be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s\n",
    "def findPositions(image):\n",
    "    positions = np.nonzero(image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "    image = cv2.rectangle(image, (left-2, top-2), (right+2, bottom+2), (0, 0, 0), 0)\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a211d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with lightining\n",
    "#model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "#lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "\n",
    "#lit_model = lit_model.load_from_checkpoint(\"Models_Parameters_Log/epoch=4-step=17280.ckpt\")\n",
    "#scripted = lit_model.to_torchscript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c64bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torch/jit/_recursive.py:262: UserWarning: 'batch_first' was found in ScriptModule constants, but was not actually set in __init__. Consider removing it.\n",
      "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n"
     ]
    }
   ],
   "source": [
    "# Load with pytorch epoch=4-step=17280.ckpt\n",
    "\n",
    "model = ResNetTransformer(dataset=dataset).to(dev)\n",
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Collate1.pth\"), map_location=torch.device('cpu')))\n",
    "lit_model = LitResNetTransformer(model=model, WandB=False)\n",
    "lit_model.freeze()\n",
    "scripted = lit_model.to_torchscript()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e136c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIZE = 1920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d376c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 116, 516])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=516x116>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { {\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { {$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "h, w, c = image.shape\n",
    "\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941ece97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=658x152>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1, 152, 658])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=658x152>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { {\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { {$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "print(display(transform(image)))\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11126f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAIAAAA+3HCUAAADMklEQVR4nNVWXyhzYRh/zmfWppWtk5qMSFMuFKlFIo3UolxZbiilcynLSpEbCnODFJ0si1pJKXdKu1JO/sQYOdyd0rnwZ05eYTvTeb+Lfc35tvOdtPUZv7v3+fN7f+/T87zvS2CM4YfgV7YFKINlWYRQkvE7ap2bm3t4eOjq6uI4Tm7PjtZAIBAMBgGA5/lUL8a4qqqqoaHh4OBAbtd8kToZNjc3EULb29tarRYhZDQaRVFMeI1Go8vlEkWRZVmXyyVPJL5+tiKRiE6nQwgNDg6urKyEQqG7u7uEt6mpKTc3d3Fx0el0IoTKy8s/MnGWIEkSTdOKrrGxMYfD0dnZubOzI7dnoa5xnJ+fi6JYW1ub6uJ5PhqNAoDFYtFqtQl7Fvo1jnA43NjYqOgqKipStGetrmngO96v/4JyD/T397e1tTmdzsw3YBhma2srFotNTU3pdDqPx7O2tvb59I6ODo/H82eROoYMwxAEMT8/n/mw7+7utra2xmKx4eHh5eXlDNmSe0CSpIWFhcLCQvmdlx5eXl56e3vHx8c1Go3JZEp6hNJAslav19vT01NSUnJ/f58h9erqqsFgqK+vBwCO4+SPkxzRaNTtdg8NDQHA/v6+CuFf/SoIwuHhIUVRNE3f3t6mRguCIAiCIhFJkvn5+XKLz+erqak5Pj4GAIZh2tvbFRP39vbcbjfP8z6fT/G6VdY6OTk5MjIS3/jy8jI1mmXZi4sLRaLq6mqbzZZYPj4+npyc1NXVBQIBhFAoFJqenlZMtNvtAGA2m5eWlvr6+lS0fszW6elpcXExRVEURVVUVJSWlmYyB0dHRzk5Oc/Pzxhjv99PkuTr66tKvCRJfr9fnVOTUDwzM3N1dZWXlwcAs7Ozo6OjqQdjGOaTdY1EIhaLxWAwAMDGxsbAwIBer1cp2fX1dVlZmVpREz3g9Xqbm5vjQgGgoKDg7e3t6ekpqQUrKyvNZrMiEUmS8qXVaiUIAgCCwSDHcevr6+o69Hq91WpVjwGe5x0OB0mSdrv9/f0dY0zTtM1mM5lMLS0tZ2dnabcBRVETExPd3d03Nzdpk8jxf/8D4XA4qd6Z4Cf9XX4D60t7gAvI710AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1, 23, 57])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAAAAACU1bgfAAABlklEQVR4nGP8z0AmYCJdy/VPZOqc8Cb0ASk695xneAph/de1PsnAwMDAQpzGtZ+2s30S+MXAwCBQ+Ot6IQMDAwMjcSH0g+NTwbxLrxgYGOxYp4V9UmZgYGD4TyT4NxPKqPX03/X/////RNrJwHD5lzGE8fQngwwb8f5kYHhrC2VIQ2mi7cQAZKQEKIC5NsUtDLuCYxt+t3N0LkIV9OlkgIXtMcaJ2IP0kMvv8tlYZSCu/TdZ8hVWG7/GNbEInsQqBdE5J1buNVbphTyWDA9+QTk/S4oZTqD68/2ptJkvIfz376ESwvwMDAwM8w3PMhzzhgodLXk63xhVZ1sVg/A1CP/6FaiEgRkDA8O7cxZ7Pl3qgAo5MUhMT0S45////xdk09LUFLCFwmnmz/+XCn9DJMGlCDkWBob/XTe4GPqrIQYdQ7HzhwwPw6o8Trg1NxURVrIwMMxx4GJgEP3+kZ+BgYFBUwLmTwYGBgZVRobzD1YgVHOqIoXeU09hpz//Z5oJOl/E4ty05ojHODIPoXT7VhiXDPkpHgC2DSlKvFKlrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { { \\, { \\, { \\, { \\, { { { { { { { { { { { { { { { { { { { { { { { { { { {\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { { \\, { \\, { \\, { \\, { { { { { { { { { { { { { { { { { { { { { { { { { { {$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "print(display(transform(image)))\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "500cd6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAIAAAA+3HCUAAADMklEQVR4nNVWXyhzYRh/zmfWppWtk5qMSFMuFKlFIo3UolxZbiilcynLSpEbCnODFJ0si1pJKXdKu1JO/sQYOdyd0rnwZ05eYTvTeb+Lfc35tvOdtPUZv7v3+fN7f+/T87zvS2CM4YfgV7YFKINlWYRQkvE7ap2bm3t4eOjq6uI4Tm7PjtZAIBAMBgGA5/lUL8a4qqqqoaHh4OBAbtd8kToZNjc3EULb29tarRYhZDQaRVFMeI1Go8vlEkWRZVmXyyVPJL5+tiKRiE6nQwgNDg6urKyEQqG7u7uEt6mpKTc3d3Fx0el0IoTKy8s/MnGWIEkSTdOKrrGxMYfD0dnZubOzI7dnoa5xnJ+fi6JYW1ub6uJ5PhqNAoDFYtFqtQl7Fvo1jnA43NjYqOgqKipStGetrmngO96v/4JyD/T397e1tTmdzsw3YBhma2srFotNTU3pdDqPx7O2tvb59I6ODo/H82eROoYMwxAEMT8/n/mw7+7utra2xmKx4eHh5eXlDNmSe0CSpIWFhcLCQvmdlx5eXl56e3vHx8c1Go3JZEp6hNJAslav19vT01NSUnJ/f58h9erqqsFgqK+vBwCO4+SPkxzRaNTtdg8NDQHA/v6+CuFf/SoIwuHhIUVRNE3f3t6mRguCIAiCIhFJkvn5+XKLz+erqak5Pj4GAIZh2tvbFRP39vbcbjfP8z6fT/G6VdY6OTk5MjIS3/jy8jI1mmXZi4sLRaLq6mqbzZZYPj4+npyc1NXVBQIBhFAoFJqenlZMtNvtAGA2m5eWlvr6+lS0fszW6elpcXExRVEURVVUVJSWlmYyB0dHRzk5Oc/Pzxhjv99PkuTr66tKvCRJfr9fnVOTUDwzM3N1dZWXlwcAs7Ozo6OjqQdjGOaTdY1EIhaLxWAwAMDGxsbAwIBer1cp2fX1dVlZmVpREz3g9Xqbm5vjQgGgoKDg7e3t6ekpqQUrKyvNZrMiEUmS8qXVaiUIAgCCwSDHcevr6+o69Hq91WpVjwGe5x0OB0mSdrv9/f0dY0zTtM1mM5lMLS0tZ2dnabcBRVETExPd3d03Nzdpk8jxf/8D4XA4qd6Z4Cf9XX4D60t7gAvI710AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1, 23, 57])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADkAAAAXCAAAAACU1bgfAAABlklEQVR4nGP8z0AmYCJdy/VPZOqc8Cb0ASk695xneAph/de1PsnAwMDAQpzGtZ+2s30S+MXAwCBQ+Ot6IQMDAwMjcSH0g+NTwbxLrxgYGOxYp4V9UmZgYGD4TyT4NxPKqPX03/X/////RNrJwHD5lzGE8fQngwwb8f5kYHhrC2VIQ2mi7cQAZKQEKIC5NsUtDLuCYxt+t3N0LkIV9OlkgIXtMcaJ2IP0kMvv8tlYZSCu/TdZ8hVWG7/GNbEInsQqBdE5J1buNVbphTyWDA9+QTk/S4oZTqD68/2ptJkvIfz376ESwvwMDAwM8w3PMhzzhgodLXk63xhVZ1sVg/A1CP/6FaiEgRkDA8O7cxZ7Pl3qgAo5MUhMT0S45////xdk09LUFLCFwmnmz/+XCn9DJMGlCDkWBob/XTe4GPqrIQYdQ7HzhwwPw6o8Trg1NxURVrIwMMxx4GJgEP3+kZ+BgYFBUwLmTwYGBgZVRobzD1YgVHOqIoXeU09hpz//Z5oJOl/E4ty05ojHODIPoXT7VhiXDPkpHgC2DSlKvFKlrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=57x23>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { { \\, { \\, { \\, { \\, { { { { { { { { { { { { { { { { { { { { { { { { { { {\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, \\, { { \\, { \\, { \\, { \\, { { { { { { { { { { { { { { { { { { { { { { { { { { {$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "print(display(transform(image)))\n",
    "\n",
    "\n",
    "h, w, c = image.shape\n",
    "if w>MAX_SIZE:\n",
    "    ratio = int(h / w)\n",
    "    new_w = 1920\n",
    "    new_h = new_w*ratio\n",
    "    img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) \n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7878d77a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_RATIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ratio \u001b[38;5;241m>\u001b[39m \u001b[43mMAX_RATIO\u001b[49m:\n\u001b[1;32m      8\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m MAX_RATIO\n\u001b[1;32m      9\u001b[0m h_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_RATIO' is not defined"
     ]
    }
   ],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58230f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "w, h = image.size\n",
    "ratio = round((w / h) * 3) \n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "h_new = 32\n",
    "w_new = h_new * ratio\n",
    "img_resize = image.resize((w_new, h_new), Image.BILINEAR)\n",
    "\n",
    "# Do padding to the right half of the image so that the ratio remain fixed as self.max_ratio\n",
    "img_padd = Image.new('RGB', (32*MAX_RATIO, 32), (0,0,0))\n",
    "img_padd.paste(img_resize, (0, 0)) \n",
    "print(img_padd.size)\n",
    "print(display(img_padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 200:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 200\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e499be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "\n",
    "aspect = h / w\n",
    "print(h,w, aspect)\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 300\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 400\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4585246",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 100\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xss(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "\n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 500\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "       \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d508b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Downscaling big images\n",
    "new_w = 500\n",
    "new_h = int(new_w * aspect)\n",
    "if w>500:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]    \n",
    "    \n",
    "#image_tensor = Image_Transforms.test_transform_with_padding_medium(image=np.array(image))['image'][:1]    \n",
    "\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f10c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "image = findPositions(image)\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 600:\n",
    "    new_w = 600\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "if w<200:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xs(image=np.array(image))['image'][:1]\n",
    "elif w < 350:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_small(image=np.array(image))['image'][:1]\n",
    "elif w<600:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "else:\n",
    "    image_tensor = Image_Transforms.test_transform_with_padding_xl(image=np.array(image))['image'][:1]\n",
    "    \n",
    "    \n",
    "    \n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "prediction =  scripted(image_tensor.unsqueeze(0))\n",
    "print(token_to_strings(prediction))\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "positions = np.nonzero(image)\n",
    "top = positions[0].min()\n",
    "bottom = positions[0].max()\n",
    "left = positions[1].min()\n",
    "right = positions[1].max()\n",
    "image = cv2.rectangle(image, (left - 2, top - 2), (right + 2, bottom + 2), (0, 0, 0), 0)\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio = (w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.train_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c03662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "\n",
    "positions = np.nonzero(image)\n",
    "top = positions[0].min()\n",
    "bottom = positions[0].max()\n",
    "left = positions[1].min()\n",
    "right = positions[1].max()\n",
    "image = cv2.rectangle(image, (left - 2, top - 2), (right + 2, bottom + 2), (0, 0, 0), 0)\n",
    "\n",
    "h, w, c = image.shape\n",
    "ratio =(w / h)\n",
    "if ratio == 0:\n",
    "    ratio = 1 \n",
    "if ratio > MAX_RATIO:\n",
    "    ratio = MAX_RATIO\n",
    "\n",
    "\n",
    "new_h = 64\n",
    "new_w = int(new_h * ratio)\n",
    "if h >64:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "else:\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    \n",
    "image_tensor = Image_Transforms.train_transform_with_padding(image=np.array(image))['image'][:1]\n",
    "print(image_tensor.shape)\n",
    "print(display(transform(image_tensor))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c166c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
