{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afce2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/Users/gregory/PROJECT_ML/PROJECT_AMINE/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07ea162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.Data_Module import Data_Module\n",
    "from Models.Printed_Tex_Transformer import ResNetTransformer\n",
    "from Lightning_Models.Printed_Tex_Lit_Model import LitResNetTransformer\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display, Math\n",
    "from Data.image_transforms import Image_Transforms\n",
    "\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb68b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Module by uploading images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "\n",
    "dataset = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 128,\n",
    "                 number_png_images_to_use_in_dataset=250*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.999,\n",
    "                   vocabulary_path = 'Data/Data_Bank/230k.json',\n",
    "                load_vocabulary = True,\n",
    "                      image_padding = True,\n",
    "\n",
    "\n",
    "                 batch_size = 128,\n",
    "                num_workers = 8,\n",
    "                data_on_gpu = True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb165d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 579 \n",
      "Max label length: 130 \n",
      "Start <S> goes to index  0 \n",
      "End <E> goes to index  1 \n",
      "Padding <P> goes to index  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmin_h: 9\\nmax_h: 177\\nmin_w: 24\\nmax_w: 512\\nmin_ratio: 0.42857142857142855\\nmax_ratio: 35.357142857142854\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(dataset.vocabulary),\n",
    "    '\\nMax label length:', dataset.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",dataset.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",dataset.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",dataset.vocabulary['<P>'],\n",
    ")\n",
    "'''\n",
    "min_h: 9\n",
    "max_h: 177\n",
    "min_w: 24\n",
    "max_w: 512\n",
    "min_ratio: 0.42857142857142855\n",
    "max_ratio: 35.357142857142854\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6c15cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gregory/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = ResNetTransformer(dataset=dataset).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4390ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load((\"Models_Parameters_Log/Printed1_2D600_350.pth\"), map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab21e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab200a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427cc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "transform = transforms.ToPILImage()\n",
    "# Helper Function to convert prediction labels to strings\n",
    "def token_to_strings(tokens):\n",
    "    mapping = dataset.vocabulary\n",
    "    inverse_mapping =dataset.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s +\" \" + str(letter)\n",
    "    return s\n",
    "def findPositions(image):\n",
    "    positions = np.nonzero(image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 0), 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ccebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa947fc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n"
     ]
    }
   ],
   "source": [
    "## ALB\n",
    "\n",
    "image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = np.asarray(image)\n",
    "image = cv2.bitwise_not(image)\n",
    "image = findPositions(image)\n",
    "h, w, c = image.shape\n",
    "aspect = h / w\n",
    "\n",
    "# Thresholding\n",
    "if w > 400:\n",
    "    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Downscaling big images\n",
    "if w > 1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w * aspect)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "image_tensor = Image_Transforms.test_transform_with_padding_medium(image=np.array(image))['image'][:1]\n",
    "print(display(transform(image_tensor)))\n",
    "\n",
    "\n",
    "\n",
    "#prediction =  scripted_model(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print('\\nPredicted formula:')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5acbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 516, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\mathrm { P e r m } ( S ) \\simeq { \\bf S } _ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\mathrm { P e r m } ( S ) \\simeq { \\bf S } _ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/zarhin.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    pass\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7f98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 658, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "print(my_image.shape)\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d149d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old 152 658\n",
      "(17, 8) (620, 132)\n",
      "new 152 658\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> p ( X = x _ { i } ) = \\sum _ { j = 1 } ^ { L } p ( X = x _ { i } , Y = y _ { j } ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_1.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "print('old',h,w)\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left-1, top-1), (right+1, bottom+1), (0,0,0), 0)\n",
    "\n",
    "print( (left, top), (right, bottom), )    \n",
    "\n",
    "#Thresholding\n",
    "ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "print('new',h,w)\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "#print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c580c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2303370786516854\n",
      "(41, 178, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> h ( a , b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { n } } \\eta ^ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> h ( a , b , c ; \\eta ) = \\sum _ { n = 0 } ^ { \\infty } \\frac { ( a ) _ { n } ( b ) _ { n } } { n ! ( c ) _ { n } } \\eta ^ { n } . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0df4c4229b725.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "positions = np.nonzero(my_image)\n",
    "top = positions[0].min()\n",
    "bottom = positions[0].max()\n",
    "left = positions[1].min()\n",
    "right = positions[1].max()\n",
    "\n",
    "my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_small(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc374a31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 57, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> A = \\theta ^ { \\frac { \\gamma - 2 } { \\gamma } <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/0a0ebebfb1f6ab3.png\"\n",
    "my_image = Image.open(my_image_path)#.convert(\"L\") \n",
    "my_image= np.asarray(my_image)\n",
    "#my_image = cv2.imread(my_image_path)\n",
    "#my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_xs(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a264888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 1080, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\rho \\left( \\frac { \\partial v } { \\partial t } + v \\cdot \\nabla v \\right) = - \\nabla p + \\nabla \\cdot T + f <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\rho \\left( \\frac { \\partial v } { \\partial t } + v \\cdot \\nabla v \\right) = - \\nabla p + \\nabla \\cdot T + f <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/screenshot_3.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test_medium(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8208dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1404494382022472\n",
      "(140, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAFeCAAAAAB8vD6AAAAMcElEQVR4nO3ce5zXc77A8dd3LjVTSVGJUs2pqOmmo3SiY9c6ri0KnZJYt5ytXZbOsSxrbWJbLJaHS1jrEiuUY50VZy3qOEgH67ZsQwhJUpnVpMvU+/zxu079ZpLjlBmv51+f2/fz/Xzn957v9/P9/D4zIEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEmSJEn6pun57PYegZqiyltjew9BTcOcj3hyRbdc3sDSVyNqiW5F5eXl5eXNqT+wotW2HJQavROCLlHav6qqqqpqBvUFVnJI7Jts24GpcfvtNC7+S15+08Aa/9AMoOg3z43LDyyDTHlOf2jzskX7sP7932WzR8WhdaonLF0UJwMxPK9wkhMx5YkFT2xe2DKhZXku26JFy/zaJHq8vAFoHjBqdMexsN/+UPwNDayi7T2Ar6nkxQKFNUHN57ns6tU1+bWTeGtAMXDiBwcU3z/jkArat2nTIdnw/zvOr62S7T2ARqWsa34u+Wud3Hm3pRLL1q3acPDcO+CszkX7/rR2241OjcE9BR6FnBvx0oKUqog4Nb+uJMZm08nCXQH2+xZfbrGr7InrfZQ0UQUDixUxKZMs+2Gcnl9VFL1yme6pJuXQrWf7rT/5+ma3vZ7NJB133voe9HVVOLBKInbJZhbWCaw/fXUPvXd/y8wXsrmqOOEr63nb8Y5bj7JOhUprj+HV4kzmp3VWqA4sNN3/Ulp27TxhwN6ZXLLHl+xm+66fbc/AmjwuP9fvxoKNUm/07erp4pH3Th2YSiUFf47fu3nJYQC8vGt+8ZljCzXO98IBOy0pVP7AM+2yD8N71tapqm64x/fKtnROmv0GgOHMf7dH7/T1JAXmaAVHljZ1TDox9Gyg/5RM+ZALP9ji+Rux4dXLFnXjoGWfXgHnXFS3btDLhY6Id9785P0FUVq4v3kzAR5auewZePyTxR02b/HhCIBXdq1besvxWznwrKKINoXKk9ivweMW7/gF7iBdlgA8HEmHGMmGtWvXrv0bECcAOy1fVv3W4rXtgNgkRA9aueztThyxYuUvSK44LVt8/DTg8D+kcy3euWrL52/EDo7P4cbXWwKrAXbK+4X8uMBHM/hfIE5n2NWFu5v3AADPxTWw4vBs8c/vyCaXjABG3wBwVN7+qS+/bDkwFhcqntzwgtW1YwAuvX8LnT//QyDuonN8l9LS0tLSUtKBxS+iN9R0gJmHb3rUoRFw5Zxm0CH/ZhZ7Aiv7ZnJDtnDuRm5RnNn/FYDZZwDF/d7N/SK3r+ezifrnC+nAYsNG7vp2trTs33+QXZ9bMgJY1RZofsG03H3v8l9mUu/lvcx9EcnzcVmB4vsbnrtHK6DZf06sd92wrKysrIh2AT1jQ3lNbu5OUZxSBNwUrdllHLRI/U40Kysry8723ohxg14AmH1stjMYMQ8YujJVkkQHKCkrK2uqK5d7xNJ5QPoG82RE5K40HVjtR40aNWrUqKPTpWNX1N9bJrCejXeOBLjlxwCxIR7NtFgygvT9KTZG7vf5vOwt642tnhxH9N68cNVnDT3qekRJagR/qKfBhIiIf6Q0OjI6fvTE7XlVD9z3x6FAxA6DHgH2CIATIyIyc9RkcHw4H4CavQFejYiA/aMYKgLg5cdqAg6MiLj+C19nIxMxEaA09cnGSflVIwCo+OXUqVOnTr04XfqDTwr28xPIBVZJRALwt3SvwK9n94RUYJ2VK83IzYn/0mVrr6B1LCverHDNuoYOufYtIKHex+XOkyvXdeoOvHMOdxd8TJdFRPQB5s8Cdp61Y1R0y9V+HOMBekQZ8GrlE6f1BoiWQE0fqDmKB2+m5M9to7JHw9fWaCWd3471ReQCK7+yzraArDUXFSi8NNZBLrAevDNuzqv8Kxx0Z6vaYlKBNSEAvruyzrkAWF5dvSGqq48D+Hk0YGD+sWdvHLXpeJrHd+q7ZIBfvQNwdZ3vFnetrq6urq4OgNKifacD8MZZRfFfhXpoH69wRAdg7u+BkuaHzsjVJXs+GjUAFdEC2DnzU42WwGe9mBVQPZ6kxYB5DQ2yUesTRBxKncC661puuRogUtPSXndPnz59+vRb04fUVsAV05uNmVlacW/u5W5IfmDde0PbiNy+g+v+DDVwd3/yA+u4pdBh+o9bz/hW5sQAvN5tqy/iT0s3K7omCryR5qQC67YVMPUuTnuwwDxnfapswY/qmVAeFSNTibmp/TwvNcvV7R2knot/F6nVmYWp8mgJrOrFm2fTMwYDdw9qaJCN2d4B+0RtM6DmGOBnHwxtnRy06t3hGyA7x2p39MiRI0eOPDJ9TGqCNG/nZfO/XZubaA9ZC5nAmvUIPBS/A7q2AojjJ7ERZowkFVg7BsDqaadCVfXt93wEnLMm09HWz7HOLLCO9KuGXzMPilJg+ZHnQixsHZ03b5Ga+5fGDvWdNA5MJUbl3er7ALBPwF7xeTNI1g0BmJ16vR4WRdA1aBVn8lnsljkofVSTclpcktAl4vEW8OzFQLzxFlQt4L9XAL0LfTgH3BNHQGXQOsY0iw4zIiLijvw71uCZsRecFXEibExF4fyD2QgzxpGevK+vAOKxc2DdDSw9Hph2X+YEC/fcumtIvhcF3iM/2djwUdEWknj8MA6JHQYXWJUbGK9MBLpEPSvWoyKmpCZ2raMEGBTPnsHecTskY+J8GBDxHyXw9ESAT18LgBMWAYcFLFoUV8VK2D3mXgtXNMEdYv0rB0K7yso+pcBGoE0fINqxpCcwt9CLf0Xfyv7ws0f4pzV0X5Arz92xOvWp7AIDKiv7kZRvBOhbAWvgmb1IB9awmZD02gOab0w/g3M/3B7ZZ8rJAHQDiI4A3BHxOE/Vme8mbJjE5lb9scELT87/V2DPXnD9rVw6t0CLQ9sCXF7f14J9Kyv3Sj8ibzoWYHRH4OCFQP/K/tCxsrJvEZR/CrDLCADe7gTM7wat+5QnfYuBIyoA+jU41MZvwoXpRNA8Lu/OPxSctKa81ZLJo3nu1dz3cQPzHoU5T12eSZ3yWLKuhHRg8VK3VOnuSxkaL8KvC32A18Wiyy+bsxioSu1OiN/zdJRRW2ejaM1PssnWmcVH2sY/1z94AD5N36XeOJLXbpxdT6M2722hl9SwMje8Fh/uuGnd5LOzyWNuBQ6Y9UV6bGLOSL3u7XEubS4sYWjB7QRp5xXzb3ty6rnZgt0uOv8c4H8WXjY4r1n+tPeSq4CJU9ak5rwLUqEyfjxDJsM1Yygk5kDpYhiRWue/IPrxXMDR+c+OqkW5dO8TM6nvR53gK2RJCwCmlDB1dD1Nygqu6RcYZwN1F5yXTgy/Dhj2TYyrr5+YAwkURWqj6PLovH/tEQmsaZ5tckHkba+afVwmNXbb/imhf/jTuMQcAFpEastMxOrVDwCszm68aldnVSGGZVIf1VmhkupIB1aXVJQcHlcmg+I+4NGP0w3axinZxgkfZx9JSfXFqA43+hWQetIM4vkIdgEiE0Hvcmt2LX5j3kNxh9bLgdOu2eYj/fpqqt91/1+k9wweyT3042Fg1+WpikmrPss2iiRvqjOAe6HNmU/v8BnSZuIxAEqjH0DESSyIMqD67+s5IBNZi1cB4+KSYfW00zdZ8zcjXgNg7vlAv1gRL9buArQs+HqfkN7I2QPiSqBfE1zR1lehpKQkNTNoG8Ax0a+0fQIw5eRCrctrL34JoG+8NHw1wJNOsbQFY2+Ah2O3VGZA7h/MtGpF9kvip85gTQKcFC+v2z2B4ti/CzNmvdd1086krDHHJplXwVZ5/7jotVgZTJg4ceLECXzanZuPBfj+jPYJUBxLMtvTpXokUFGgeHzQjk6dO3fu3Kk4unPTw5s2WL4Nxqam5/1pQFFRUVFREcu7c8OmX/qNarIbyrea3zptjUiA7yQQPDH/zuui2frtPSI1BUPzvxFsE1PGb7eRqOnyXi9JkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJkiRJktTk/S9GwvGs5dGp4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\chi _ { ( \\mu _ { n } ) = \\prod _ { m - 1 ! ( X ; t _ { 0 } ) ( t _ { n } ) + \\frac { 1 } { \\Gamma ( g ) } \\sum _ { r = 0 } ^ { 2 - 1 } \\int _ { t } ^ { t . 1 } f _ { a } - \\tau ( \\tau , X ( \\tau ) d \\tau } <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\chi _ { ( \\mu _ { n } ) = \\prod _ { m - 1 ! ( X ; t _ { 0 } ) ( t _ { n } ) + \\frac { 1 } { \\Gamma ( g ) } \\sum _ { r = 0 } ^ { 2 - 1 } \\int _ { t } ^ { t . 1 } f _ { a } - \\tau ( \\tau , X ( \\tau ) d \\tau } <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_14.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(h/w)\n",
    "\n",
    "if w>1200:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "584d011a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 1774, 3)\n",
      "(136, 1200, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> X ( r _ { \\mu } ) = l _ { a - i \\chi _ { i } 0 } ( t _ { o } ) + \\frac { 1 } { 1 ( g ) } \\sum _ { + 0 } ^ { 4 + } f _ { a } - \\tau ) \\theta _ { i } ^ { \\ell + } r ( \\tau , v ) d \\tau } \\qquad \\qquad \\qquad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad X ( b ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> X ( r _ { \\mu } ) = l _ { a - i \\chi _ { i } 0 } ( t _ { o } ) + \\frac { 1 } { 1 ( g ) } \\sum _ { + 0 } ^ { 4 + } f _ { a } - \\tau ) \\theta _ { i } ^ { \\ell + } r ( \\tau , v ) d \\tau } \\qquad \\qquad \\qquad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad X ( b ) <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_13.png\"\n",
    "#my_image = Image.open(my_image_path)#.convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "    \n",
    "\n",
    "\n",
    "h,w,c = my_image.shape\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "print(my_image.shape)\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1200\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "859b5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 1950, 3)\n",
      "(96, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Predicted formula:\n",
      " <S> \\chi _ { v } \\rightarrow \\gamma ^ { \\prime } * \\gamma _ { \\nu } ^ { p } * \\gamma _ { \\nu } ^ { 9 } . \\sum _ { x i } e \\int _ { x l } v ^ { 9 } + \\sum _ { z \\nu } e \\int _ { \\sigma \\mu \\alpha \\beta } + \\sum _ { \\varphi } ^ { 5 } A _ { \\sigma \\mu ( \\alpha ) } \\quad v ^ { * + \\nu * + \\gamma + \\chi - s _ { 2 } - \\omega . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle  <S> \\chi _ { v } \\rightarrow \\gamma ^ { \\prime } * \\gamma _ { \\nu } ^ { p } * \\gamma _ { \\nu } ^ { 9 } . \\sum _ { x i } e \\int _ { x l } v ^ { 9 } + \\sum _ { z \\nu } e \\int _ { \\sigma \\mu \\alpha \\beta } + \\sum _ { \\varphi } ^ { 5 } A _ { \\sigma \\mu ( \\alpha ) } \\quad v ^ { * + \\nu * + \\gamma + \\chi - s _ { 2 } - \\omega . <E> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P> <P>$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### ALB\n",
    "\n",
    "my_image_path= \"Jupyter_Notebooks/test_photos/Screen Shot_10.png\"\n",
    "#my_image = Image.open(my_image_path).convert(\"L\") \n",
    "my_image = cv2.imread(my_image_path)\n",
    "my_image =  cv2.cvtColor(my_image, cv2.COLOR_BGR2RGB)\n",
    "my_image= cv2.bitwise_not(my_image)\n",
    "#my_image = PIL.ImageOps.invert(my_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Thresholding\n",
    "#ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "non_zero = True\n",
    "\n",
    "# Find first non_zero pixel and crop to it\n",
    "if non_zero:\n",
    "    positions = np.nonzero(my_image)\n",
    "    top = positions[0].min()\n",
    "    bottom = positions[0].max()\n",
    "    left = positions[1].min()\n",
    "    right = positions[1].max()\n",
    "\n",
    "    my_image = cv2.rectangle(my_image, (left, top), (right, bottom), (0,0,0), 0)\n",
    "print(my_image.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if w>400:\n",
    "    #Thresholding\n",
    "    ret,my_image = cv2.threshold(my_image,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "h,w,c = my_image.shape\n",
    "aspect = h/w\n",
    "\n",
    "\n",
    "if w>1600:\n",
    "    new_w = 1000\n",
    "    new_h = int(new_w*aspect)\n",
    "    my_image= cv2.resize(my_image, (new_w, new_h), interpolation= cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "print(my_image.shape)\n",
    "\n",
    "my_image_tensor = dataset.image_transform_test(image=np.array(my_image))['image'][:1]\n",
    "print(display(transform(my_image_tensor)))\n",
    "model.eval()\n",
    "print('\\nPredicted formula:')\n",
    "with torch.no_grad():\n",
    "    my_prediction =  model.predict(my_image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(my_prediction))\n",
    "print(display(Math(token_to_strings(my_prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09bd905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f8af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32c5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad0486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d878f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fbb5059",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data_Module' object has no attribute 'data_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DISREGARD this uses wrong transformations\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get image and label from train data -- change number for different ones\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m image_tensor, label \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_train\u001b[49m[\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m transform(image_tensor)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data_Module' object has no attribute 'data_train'"
     ]
    }
   ],
   "source": [
    "# DISREGARD this uses wrong transformations\n",
    "\n",
    "# Get image and label from train data -- change number for different ones\n",
    "image_tensor, label = dataset.data_train[12]\n",
    "transform = transforms.ToPILImage()\n",
    "image = transform(image_tensor)\n",
    "\n",
    "print('\\nOriginal image and formula:')\n",
    "display(image)\n",
    "print(token_to_strings(label))\n",
    "print('\\nPredicted formula: \\n')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    prediction =  model.predict(image_tensor.unsqueeze(0).to(dev))\n",
    "print(token_to_strings(prediction),'\\n')\n",
    "print(display(Math(token_to_strings(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d738f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39597f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db861789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf6bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb316f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
