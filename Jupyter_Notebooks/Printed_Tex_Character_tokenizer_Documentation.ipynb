{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9b8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting path:/home/tigranerfaceb/image-to-tex-OCR/Jupyter_Notebooks\n",
      "Current path:/home/tigranerfaceb/image-to-tex-OCR\n"
     ]
    }
   ],
   "source": [
    "# Here we take care of paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "print('Starting path:' + os.getcwd())\n",
    "if os.getcwd()[-16:] == 'image-to-tex-OCR':\n",
    "    pass\n",
    "else:\n",
    "    PATH = Path().resolve().parents[0]\n",
    "    os.chdir(PATH)\n",
    "\n",
    "# make sure you are in Paragraph_to_Tex folder\n",
    "print('Current path:' + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a00ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Printed_Tex_Data_Module\n",
    "\n",
    "from Data.Data_Module import Data_Module\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from IPython.display import display, Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897003e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Module(stage = 'fit',\n",
    "                 set_max_label_length = 256,\n",
    "                 number_png_images_to_use_in_dataset=200*1000,\n",
    "                 labels_transform='default',\n",
    "                image_transform_name ='alb',\n",
    "                 train_val_fraction = 0.95,\n",
    "                   \n",
    "                load_vocabulary = False,\n",
    "\n",
    "\n",
    "                 batch_size = 64,\n",
    "                num_workers = 10,\n",
    "                data_on_gpu = False,\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "# Generates the dataframe from the images and formulas\n",
    "# images need to be in the folder Data/Data_Bank/generated_png_images\n",
    "# formulas need to be in Data/Data_Bank/final_png_formulas.txt\n",
    "# image filenames need to be in Data/Data_Bank/corresponding_png_images.txt\n",
    "data.prepare_dataframe()\n",
    "\n",
    "# if one wants to load a vocabulary do not use data.prepare_dataframe(), \n",
    "# but instead set load_vocabulary = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707addc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e07d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \n",
    "    'Vocabulary size:',len(data.vocabulary),\n",
    "    '\\nMax label length:', data.max_label_length,\n",
    "    \"\\nStart <S> goes to index \",data.vocabulary['<S>'],\n",
    "      \"\\nEnd <E> goes to index \",data.vocabulary['<E>'],\n",
    "      \"\\nPadding <P> goes to index \",data.vocabulary['<P>'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c38997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepeares the dataloaders with transformations and splits train/val\n",
    "data.setup_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da00227",
   "metadata": {},
   "source": [
    "# Checking the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faef229",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.df['image_name'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7aa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to access generated png images \n",
    "IMAGE_NAME = data.df['image_name'][10]\n",
    "image_path= \"Data/Data_Bank/generated_png_images/\" + IMAGE_NAME\n",
    "image = Image.open(image_path)#.convert(\"L\")\n",
    "print('Image is below')\n",
    "display(image)\n",
    "\n",
    "# Related Label\n",
    "\n",
    "image_label_list = data.df[data.df['image_name'] ==  IMAGE_NAME]['formula'].tolist()#.item()\n",
    "image_label = \" \".join(image_label_list)\n",
    "print('Label:')\n",
    "display(Math(image_label))\n",
    "print('Tex formula: \\n')\n",
    "print(data.df[data.df['image_name'] == IMAGE_NAME]['formula'].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1519ec35",
   "metadata": {},
   "source": [
    "### Check  vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72dc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can acrtually see the frequncies\n",
    "\n",
    "data.data_server.vocabulary_dataframe.sort_values(\"freq\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of vocabulary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first order the columns by decsending frequncy \n",
    "data.data_server.vocabulary_dataframe = data.data_server.vocabulary_dataframe.sort_values(\"freq\", ascending=False)\n",
    "\n",
    "# next we plot them\n",
    "data.data_server.vocabulary_dataframe.plot(x=\"token\", y='freq', kind='barh', figsize =(16,75))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db840e",
   "metadata": {},
   "source": [
    "#### Look at the distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20693f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We plot the tokenized len distribution\n",
    "\n",
    "tokenized_len = data.df['tokenized_len'].value_counts()\n",
    "tokenized_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long are formulas\n",
    "plt.figure(figsize=(40,5))\n",
    "sns.countplot(x=data.df['tokenized_len']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3be26",
   "metadata": {},
   "source": [
    "## Acessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to convert prediction labels to strings\n",
    "def token_to_strings(tokens):\n",
    "    mapping = data.vocabulary\n",
    "    inverse_mapping =data.inverse_vocabulary\n",
    "    s=''\n",
    "    if tokens.shape[0] ==1:\n",
    "        tokens = tokens[0]\n",
    "    for number in tokens:\n",
    "        letter = inverse_mapping[number.item()]\n",
    "        s= s + str(letter)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05626e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToPILImage()\n",
    "display(transform(data.data_train[1][0]))\n",
    "print(token_to_strings(data.data_train[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ebf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98207c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09accc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
